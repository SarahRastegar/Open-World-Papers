<!----------------------------------------------------------------------------------------------------------------------------------------------->
# Video Open World Papers
<!----------------------------------------------------------------------------------------------------------------------------------------------->
## Contents
- [Zero-Shot Learning Videos](#Zero-Shot-Learning-Videos)  
- [Out-of-Distribution Detection Videos](#Out-of-Distribution-Detection-Videos) 
- [Open-Set Recognition Videos](#Open-Set-Recognition-Videos)
- [Novel Class Discovery Videos](#Novel-Class-Discovery-Videos)
- [Open Vocabulary Videos](#Open-Vocabulary-Videos)
- [Fine Grained Videos](#Fine-Grained-Videos)
- [Long Tail Videos](#Long-Tail-Videos)
- [Anomaly Detection Videos](#Anomaly-Detection-Videos)
- [Novelty Detection](#Novelty-Detection)
- [Other Related Papers](#Other-Related-Papers)
- [Action Recognition Related](#Action-Recognition-Related)
<!----------------------------------------------------------------------------------------------------------------------------------------------->
## Zero-Shot Learning Videos
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### Surveys
* Zero-Shot Action Recognition in Videos: A Survey (Neurocomputing 2021) 
[[Paper](https://arxiv.org/abs/1909.06423)]<br>

* A Review of Generalized Zero-Shot Learning Methods (TPAMI 2022) 
[[Paper](https://arxiv.org/abs/2011.08641)]<br>

* Generalized Zero-Shot Learning for Action Recognition with Web-Scale Video Data (Arxiv 2017) 
[[Paper](https://arxiv.org/abs/1710.07455)]<br>

### 2023 Papers
<!-- #### CVPR
#### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw-->
#### WACV

* Language-Free Training for Zero-Shot Video Grounding (WACV 2023) 
[[Paper](http://arxiv.org/abs/2210.12977)]<br>
*Datasets: Charades-STA, ActivityNet Captions*<br>
*Task: Video Grounding*

* Semantics Guided Contrastive Learning of Transformers for Zero-Shot Temporal Activity Detection (WACV 2023) 
[[Paper](https://openaccess.thecvf.com/content/WACV2023/papers/Nag_Semantics_Guided_Contrastive_Learning_of_Transformers_for_Zero-Shot_Temporal_Activity_WACV_2023_paper.pdf)]<br>
*Datasets: Thumosâ€™14 and Charades*<br>
*Task: Action Recognition*
<!--#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2022 Papers
#### CVPR
* Uni-Perceiver: Pre-Training Unified Architecture for Generic Perception for Zero-Shot and Few-Shot Tasks (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Uni-Perceiver_Pre-Training_Unified_Architecture_for_Generic_Perception_for_Zero-Shot_and_CVPR_2022_paper.pdf)]<br>
*Datasets: ImageNet-21k;  Kinetics-700 and Moments in Time;  BookCorpora & English  Wikipedia  (Books&Wiki)  and  PAQ; COCO Caption, SBUCaptions  (SBU),  Visual  Genome,  CC3M, CC12M and YFCC; Flickr30k, MSVD,VQA ,and GLUE*<br>
*Task: Image-Text Retreival; Image and Video Classification*

* Cross-Modal Representation Learning for Zero-Shot Action Recognition (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Cross-Modal_Representation_Learning_for_Zero-Shot_Action_Recognition_CVPR_2022_paper.pdf)]
[[Code](https://github.com/microsoft/ResT)]<br>
*Datasets: Kinetics ->  UCF101, HMDB51, and ActivityNet*<br>
*Task: Action Recognition*

* Audio-Visual Generalised Zero-Shot Learning With Cross-Modal Attention and Language (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Mercea_Audio-Visual_Generalised_Zero-Shot_Learning_With_Cross-Modal_Attention_and_Language_CVPR_2022_paper.pdf)]
[[Code](https://github.com/ExplainableML/AVCA-GZSL)]<br>
*Datasets: VGGSound; UCF101; ActivityNet*<br>
*Task: Action Recognition*

* Alignment-Uniformity Aware Representation Learning for Zero-Shot Video Classification (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Pu_Alignment-Uniformity_Aware_Representation_Learning_for_Zero-Shot_Video_Classification_CVPR_2022_paper.pdf)]
[[Code](https://github.com/ShipuLoveMili/CVPR2022-AURL)]<br>
*Datasets: Kinetics-700 -> UCF101, HMDB51*<br>
*Task: Action Recognition*

<!-- #### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access-->
#### ECCV
* Temporal and cross-modal attention foraudio-visual zero-shot learning (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136800474.pdf)]
[[Code](https://github.com/ExplainableML/TCAF-GZSL)]<br>
*Datasets: UCF-GZSL^cls, VGGSound-GZSL^cls, and ActivityNet-GZSL^cls1*<br>
*Task: Action Recognition*

* CLASTER: Clustering with Reinforcement Learning for Zero-Shot Action Recognition (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136800177.pdf)]
[[Code](https://sites.google.com/view/claster-zsl/home)]<br>
*Datasets: Olympic Sports; UCF-101; HMDB-51*<br>
*Task: Action Recognition*

* Rethinking Zero-Shot Action Recognition: Learning from Latent Atomic Actions (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136640102.pdf)]<br>
*Datasets: KineticsZSAR, HMDB51, and UCF101*<br>
*Task: Action Recognition*

* Zero-Shot Temporal Action Detection via Vision-Language Prompting (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136630667.pdf)]
[[Code](https://github.com/sauradip/STALE)]<br>
*Datasets: THUMOS14; ActivityNet v1.3*<br>
*Task: Temporal Action Detection (TAD)*
<!--#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2021 Papers
#### CVPR
* Recognizing Actions in Videos From Unseen Viewpoints (CVPR 2021) 
[[Paper](http://arxiv.org/abs/2103.16516)]<br>
*Datasets: Human3.6M, MLB-YouTube, Toyota SmartHome (TSH), NTU-RGB-D*<br>
*Task: Action Recognition*
<!-- #### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV-->
#### BMVC

* Zero-Shot Action Recognition from Diverse Object-Scene Compositions (BMVC 2021) 
[[Paper](https://www.bmvc2021-virtualconference.com/assets/papers/0739.pdf)]
[[Code](https://github.com/carlobretti/object-scene-compositions-for-actions)]<br>
*Datasets: UCF-101, Kinetics-400*<br>
*Task: Action Recognition*


<!--#### ICCw
#### Arxiv & Others-->

### Older Papers

* Out-Of-Distribution Detection for Generalized Zero-Shot Action Recognition (CVPR 2019) 
[[Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Mandal_Out-Of-Distribution_Detection_for_Generalized_Zero-Shot_Action_Recognition_CVPR_2019_paper.pdf)]
[[Code](https://github.com/naraysa/gzsl-od)]<br>
*Datasets: Olympic Sports, HMDB51 and UCF101*<br>
*Task: Action Recognition*

* Towards Universal Representation for Unseen Action Recognition (CVPR 2018) 
[[Paper](http://arxiv.org/abs/1803.08460)]<br>
*Datasets: ActivityNet, HMDB51 and UCF101*<br>
*Task: Action Recognition*

<!----------------------------------------------------------------------------------------------------------------------------------------------->
## Out-of-Distribution Detection Videos
<!----------------------------------------------------------------------------------------------------------------------------------------------->

### 2023 Papers
#### CVPR
* Towards Generalisable Video Moment Retrieval: Visual-Dynamic Injection to Image-Text Pre-Training (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2303.00040)]
<!-- #### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2022 Papers
#### CVPR
* Unknown-Aware Object Detection: Learning What You Don't Know From Videos in the Wild (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Du_Unknown-Aware_Object_Detection_Learning_What_You_Dont_Know_From_Videos_CVPR_2022_paper.pdf)]
[[Code](https://github.com/deeplearning-wisc/stud)]<br>
*Datasets: (Videos -> Images) BDD100K and Youtube-Video Instance Segmentation(Youtube-VIS)  2021 (ID) - MS-COCO and nuImages (OOD)*<br>
*Task: Object Detection*
<!-- #### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->
<!----------------------------------------------------------------------------------------------------------------------------------------------->
<!--### 2021 Papers
 #### CVPR
#### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### Older Papers
* Uncertainty-aware audiovisual activity recognition using deep bayesian variational inference (ICCV 2019) 
[[Paper](https://arxiv.org/pdf/1811.10811v3.pdf)]<br>
*Datasets: MiT*<br>
*Task: Audiovisual Action Recognition*

* Bayesian activity recognition using variational inference (NeurIPS 2018) 
[[Paper](https://arxiv.org/pdf/1811.03305v2.pdf)]<br>
*Datasets:  MiT video activity recognition dataset*<br>
*Task: Action Recognition*

* Out-Of-Distribution Detection for Generalized Zero-Shot Action Recognition (CVPR 2019) 
[[Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Mandal_Out-Of-Distribution_Detection_for_Generalized_Zero-Shot_Action_Recognition_CVPR_2019_paper.pdf)]
[[Code](https://github.com/naraysa/gzsl-od)]<br>
*Datasets: Olympic Sports, HMDB51 and UCF101*<br>
*Task: Action Recognition*

<!----------------------------------------------------------------------------------------------------------------------------------------------->
##  Open-Set Recognition Videos
<!----------------------------------------------------------------------------------------------------------------------------------------------->

### 2023 Papers
#### CVPR

* Enlarging Instance-specific and Class-specific Information for Open-set Action Recognition (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2303.15467)]

* AutoLabel: CLIP-based framework for Open-set Video Domain Adaptation (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2304.01110)]

* Open Set Action Recognition via Multi-Label Evidential Learning (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2303.12698)]

* OpenGait: Revisiting Gait Recognition Towards Better Practicality (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2211.06597)]

* Open-Category Human-Object Interaction Pre-training via Language Modeling Framework (CVPR 2023) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Zheng_Open-Category_Human-Object_Interaction_Pre-Training_via_Language_Modeling_Framework_CVPR_2023_paper.html)]

* SUDS: Scalable Urban Dynamic Scenes (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2303.14536)]

<!-- #### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw-->
#### WACV
* Reconstructing Humpty Dumpty: Multi-Feature Graph Autoencoder for Open Set Action Recognition (WACV 2023) 
[[Paper](http://arxiv.org/abs/2212.06023)]
[[Code](https://github.com/Kitware/graphautoencoder)]<br>
*Datasets:  HMDB-51, UCF-101*<br>
*Task: Action Recognition*
<!--#### IJCV
#### BMVC
#### ICCw-->
#### Arxiv & Others

* Video Instance Segmentation in an Open-World (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2304.01200)]

* Plan4MC: Skill Reinforcement Learning and Planning for Open-World Minecraft Tasks (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.16563)]

* POAR: Towards Open-World Pedestrian Attribute Recognition (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.14643)]

* Learning to Operate in Open Worlds by Adapting Planning Models (AAMAS 2023) 
[[Paper](https://arxiv.org/abs/2303.14272)]

* PyReason: Software for Open World Temporal Logic (AAAI 2023) 
[[Paper](https://arxiv.org/abs/2302.13482)]

* NovPhy: A Testbed for Physical Reasoning in Open-world Environments (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.01711)]

* Improving Audio-Visual Video Parsing with Pseudo Visual Labels (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.02344)]

* Open-World Object Manipulation using Pre-trained Vision-Language Models (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.00905)]

* Towards Generalized Robot Assembly through Compliance-Enabled Contact Formations (ICRA 2023) 
[[Paper](https://arxiv.org/abs/2303.05565)]

* Discovering Novel Actions in an Open World with Object-Grounded Visual Commonsense Reasoning (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2305.16602)]

* Temporal-controlled Frame Swap for Generating High-Fidelity Stereo Driving Data for Autonomy Analysis (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2306.01704)]


<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2022 Papers
#### CVPR
* Opening Up Open World Tracking (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Opening_Up_Open_World_Tracking_CVPR_2022_paper.pdf)]
[[Code](https://openworldtracking.github.io)]<br>
*Datasets: TAO-OW*<br>
*Task: Object Tracking*

* OpenTAL: Towards Open Set Temporal Action Localization (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_OpenTAL_Towards_Open_Set_Temporal_Action_Localization_CVPR_2022_paper.pdf)]
[[Code](https://www.rit.edu/actionlab/opental)]<br>
*Datasets: THUMOS14, ActivityNet1.3*<br>
*Task: Temporal Action Localization*

* UBnormal: New Benchmark for Supervised Open-Set Video Anomaly Detection (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Acsintoae_UBnormal_New_Benchmark_for_Supervised_Open-Set_Video_Anomaly_Detection_CVPR_2022_paper.pdf)]
[[Code](https://github.com/lilygeorgescu/UBnormal)]<br>
*Datasets: UBnormal, CHUK, Avenue, Shang-hai Tech*<br>
*Task: Anomaly Detection*

* Open-World Instance Segmentation: Exploiting Pseudo Ground Truth From Learned Pairwise Affinity (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Open-World_Instance_Segmentation_Exploiting_Pseudo_Ground_Truth_From_Learned_Pairwise_CVPR_2022_paper.pdf)]<br>
*Datasets: COCO 17, LVIS, UVO (videos), ADE20k*<br>
*Task: Instance Segmentation*


<!--#### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access-->
#### ECCV
* Towards Open Set Video Anomaly Detection (ECCV 2022) 
[[Paper](https://arxiv.org/pdf/2208.11113v1.pdf)]<br>
*Datasets: XD Violence, UCF Crime, ShanghaiTech Campus*<br>
*Task: Anomaly Detection*

<!--#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw-->
#### Arxiv & Others
* Human Activity Recognition in an Open World (Submitted to JAIR 2022) 
[[Paper](https://arxiv.org/abs/2212.12141)]

* Self-Initiated Open World Learning for Autonomous AI Agents (AAAI 2022 Spring Symposium Series) 
[[Paper](https://arxiv.org/abs/2110.11385)] 

* UVO Challenge on Video-based Open-World Segmentation 2021: 1st Place Solution (Arxiv 2022) 
[[Paper](https://arxiv.org/abs/2110.11661)] 

<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2021 Papers
#### CVPR
* Generalizing to the Open World: Deep Visual Odometry With Online Adaptation (CVPR 2021) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Generalizing_to_the_Open_World_Deep_Visual_Odometry_With_Online_CVPR_2021_paper.pdf)]<br>
*Datasets: Cityscapes,  KITTI, indoor TUM, NYUv2*<br>
*Task: Depth Estimation*


<!--#### ICLR
#### NeurIPS-->
#### ICCV
* Evidential Deep Learning for Open Set Action Recognition (ICCV 2021) 
[[Paper](https://arxiv.org/pdf/2107.10161v2.pdf)]
[[Code](https://www.rit.edu/actionlab/dear)]<br>
*Datasets: UCF-101, HMDB-51, MiT-v2*<br>
*Task: Action Recognition*

* Unidentified Video Objects: A Benchmark for Dense, Open-World Segmentation (ICCV 2021) 
[[Paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Unidentified_Video_Objects_A_Benchmark_for_Dense_Open-World_Segmentation_ICCV_2021_paper.pdf)]<br>
*Datasets: UVO, COCO*<br>
*Task: Video Object Detection and Segmentation*

<!-- #### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->

* Conditional Extreme Value Theory for Open Set Video Domain Adaptation (MMAsia 2021) 
[[Paper](https://dl.acm.org/doi/10.1145/3469877.3490600)]<br>

* Dual Metric Discriminator for Open Set Video Domain Adaptation (ICASSP 2021) 
[[Paper](https://ieeexplore.ieee.org/document/9413361)]<br> 

* Open-World Active Learning with Stacking Ensemble for Self-Driving Cars (Arxiv 2021) 
[[Paper](https://arxiv.org/abs/2109.06628)] 

* Physical Reasoning in an Open World (ACS 2021) 
[[Paper](https://arxiv.org/abs/2201.08950)] 

* Person Re-identification based on Robust Features in Open-world (Arxiv 2021) 
[[Paper](https://arxiv.org/abs/2102.10798)] 

* Online Action Recognition (AAAI 2021) 
[[Paper](https://arxiv.org/abs/2012.07464)] 

* ViNG: Learning Open-World Navigation with Visual Goals (ICRA 2021) 
[[Paper](https://arxiv.org/abs/2012.09812)] 

<!----------------------------------------------------------------------------------------------------------------------------------------------->
### Older Papers
* Specifying weight priors in bayesian deep neural networks with empirical bayes (AAAI 2020) 
[[Paper](https://arxiv.org/pdf/1906.05323v3.pdf)]<br>
*Datasets: UCF-101, Urban Sound 8K, MNIST, Fashion-MNIST, CIFAR10*<br>
*Task: Image and Audio Classification, Video Activity Recognition*

* P-ODN: prototype-based open Deep network for open Set Recognition (Scientific Reports 2020) 
[[Paper](https://www.nature.com/articles/s41598-020-63649-6)]<br>
*Datasets: UCF11, UCF50, UCF101 and HMDB51*<br>
*Task: Action Recognition*

* Uncertainty-aware audiovisual activity recognition using deep bayesian variational inference (ICCV 2019) 
[[Paper](https://arxiv.org/pdf/1811.10811v3.pdf)]<br>
*Datasets: MiT*<br>
*Task: Audiovisual Action Recognition*

* Bayesian activity recognition using variational inference (NeurIPS 2018) 
[[Paper](https://arxiv.org/pdf/1811.03305v2.pdf)]<br>
*Datasets:  MiT video activity recognition dataset*<br>
*Task: Action Recognition*

* ODN: Opening the deep network for open-set action recognition (ICME 2018) 
[[Paper](https://arxiv.org/pdf/1901.07757v1.pdf)]<br>
*Datasets:  HMDB51, UCF50, UCF101*<br>
*Task: Action Recognition*

* Open-World Stereo Video Matching with Deep RNN (ECCV 2018) 
[[Paper](https://www.ecva.net/papers/eccv_2018/papers_ECCV/papers/Yiran_Zhong_Open-World_Stereo_Video_ECCV_2018_paper.pdf)]<br>
*Datasets: KITTI VO, Middlebury Stereo 2005 & 2006, Freiburg Sceneflow, Random dot, Synthia*<br>
*Task: Stereo Video Matching*

* Adversarial Open-World Person Re-Identification (ECCV 2018) 
[[Paper](https://www.ecva.net/papers/eccv_2018/papers_ECCV/papers/Xiang_Li_Adversarial_Open-World_Person_ECCV_2018_paper.pdf)]<br>
*Datasets: Market-1501, CUHK01, CUHK03*<br>
*Task: Person Re-Identification*

* From Open Set to Closed Set: Counting Objects by Spatial Divide-and-Conquer (ICCV 2019) 
[[Paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Xiong_From_Open_Set_to_Closed_Set_Counting_Objects_by_Spatial_ICCV_2019_paper.pdf)]
[[Code](https://github.com/xhp-hust-2018-2011/S-DCNet)]<br>
*Datasets: Synthesized Cell Counting, UCF-QNRF, ShanghaiTech, UCFCC50, TRANCOS and MTC*<br>
*Task: Visual Counting*

* AutOTranS: an Autonomous Open World Transportation System (Arxiv 2018) 
[[Paper](https://arxiv.org/abs/1810.03400)] 

* From Known to the Unknown: Transferring Knowledge to Answer Questions about Novel Visual and Semantic Concepts (Arxiv 2018) 
[[Paper](https://arxiv.org/abs/1811.12772)] 

* Visual Curiosity: Learning to Ask Questions to Learn Visual Recognition (CoRL 2018 Oral) 
[[Paper](https://arxiv.org/abs/1810.00912)] 

* Towards Large-Scale Video Video Object Mining (ECCVw 2018) 
[[Paper](https://arxiv.org/abs/1809.07316)] 

<!----------------------------------------------------------------------------------------------------------------------------------------------->
##  Novel Class Discovery Videos
<!----------------------------------------------------------------------------------------------------------------------------------------------->

### 2023 Papers
#### CVPR

* Open-Category Human-Object Interaction Pre-training via Language Modeling Framework (CVPR 2023) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Zheng_Open-Category_Human-Object_Interaction_Pre-Training_via_Language_Modeling_Framework_CVPR_2023_paper.html)]
<!-- #### ICLR
#### NeurIPS
#### ICCV
#### ICML

* AnoDDPM: Anomaly Detection With Denoising Diffusion Probabilistic Models Using Simplex Noise (CVPRw 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022W/NTIRE/papers/Wyatt_AnoDDPM_Anomaly_Detection_With_Denoising_Diffusion_Probabilistic_Models_Using_Simplex_CVPRW_2022_paper.pdf)]
[[Code](https://github.com/Julian-Wyatt/AnoDDPM)]<br>
*Datasets: MVTec AD*<br>
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw-->
#### Arxiv & Others

* NEV-NCD: Negative Learning, Entropy, and Variance regularization based novel action categories discovery (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2304.07354)]
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2022 Papers
<!-- #### CVPR
#### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access-->
#### ECCV
* Text-based Temporal Localization of Novel Events (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136740552.pdf)]<br>
*Datasets: Charades-STA Unseen, ActivityNet Captions Unseen*<br>
*Task: Temporal Action Localization*

* Discovering Objects That Can Move (ECCV 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_Discovering_Objects_That_Can_Move_CVPR_2022_paper.pdf)]
[[Code](https://github.com/zpbao/Discovery_Obj_Move)]<br>
*Datasets: KITTI; CATER; TRI-PD*<br>
*Task: Object Segmentation*
<!--#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2021 Papers
<!-- #### CVPR
#### ICLR
#### NeurIPS-->
#### ICCV
* Joint Representation Learning and Novel Category Discovery on Single- and Multi-Modal Data (ICCV 2021) 
[[Paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Jia_Joint_Representation_Learning_and_Novel_Category_Discovery_on_Single-_and_ICCV_2021_paper.pdf)]<br>
*Datasets: ImageNet; CIFAR-10/CIFAR-100; Kinetics-400; VGG-Sound*<br>
*Task: Multimodal Data*

* Learning To Better Segment Objects From Unseen Classes With Unlabeled Videos (ICCV 2021) 
[[Paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Du_Learning_To_Better_Segment_Objects_From_Unseen_Classes_With_Unlabeled_ICCV_2021_paper.pdf)]
[[Code](https://dulucas.github.io/gbopt)]<br>
*Datasets: COCO -> Unseen-VIS; DAVIS*<br>
*Task: Instance Segmentation*
<!--#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV-->
#### BMVC

* Unsupervised Discovery of Actions in Instructional Videos (BMVC 2021) 
[[Paper](https://www.bmvc2021-virtualconference.com/assets/papers/0773.pdf)]<br>
*Datasets: 50-salads dataset, Narrated Instructional Videos (NIV) dataset, Breakfast dataset*<br>
*Task: Action Discovery*

<!--#### ICCw
#### Arxiv & Others-->
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### Older Papers

* Tracking the Known and the Unknown by Leveraging Semantic Information (BMVC 2019) 
[[Paper](https://bmvc2019.org/wp-content/papers/1003.html)]
[[Code](https://tracking.vision.ee.ethz.ch/track-known-unknown/)]<br>
*Datasets: NFS, UAV123, LaSOT, TrackingNet, VOT2018*<br>
*Task: Object Tracking*

* DetectFusion: Detecting and Segmenting Both Known and Unknown Dynamic Objects in Real-time SLAM (BMVC 2019) 
[[Paper](https://bmvc2019.org/wp-content/papers/0499.html)]<br>
*Datasets: TUM-RGB-D, MS COCO, PASCAL VOC*<br>
*Task: Object Tracking and Segmentation*

* Localizing Novel Attended Objects in Egocentric Views (BMVC 2020) 
[[Paper](https://www.bmvc2020-conference.com/assets/papers/0014.pdf)]<br>
*Datasets: GTEA Gaze+, Toy Room*<br>
*Task: Novel Object Localization*

* Video Face Clustering With Unknown Number of Clusters (ICCV 2019) 
[[Paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Tapaswi_Video_Face_Clustering_With_Unknown_Number_of_Clusters_ICCV_2019_paper.pdf)]
[[Code](https://github.com/makarandtapaswi/BallClustering_ICCV2019)]<br>
*Datasets: MovieGraphs, The Big Bang Theory (BBT) and Buffy the Vampire Slayer (BUFFY)*<br>
*Task: Face Clustering*

* Incremental Class Discovery for Semantic Segmentation With RGBD Sensing (ICCV 2019) 
[[Paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Nakajima_Incremental_Class_Discovery_for_Semantic_Segmentation_With_RGBD_Sensing_ICCV_2019_paper.pdf)]<br>
*Datasets: NYUDv2*<br>
*Task: Semantic Segmentation*

* Object Discovery in Videos as Foreground Motion Clustering (ICCV 2019) 
[[Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Xie_Object_Discovery_in_Videos_as_Foreground_Motion_Clustering_CVPR_2019_paper.pdf)]<br>
*Datasets: Flying Things 3d (FT3D), DAVIS2016, Freibug-Berkeley motion segmentation, Complex Background, and Camouflaged Animal*<br>
*Task: Object Discovery*


<!----------------------------------------------------------------------------------------------------------------------------------------------->
## Open Vocabulary Videos
<!----------------------------------------------------------------------------------------------------------------------------------------------->

### 2023 Papers
#### CVPR

* Open-Category Human-Object Interaction Pre-training via Language Modeling Framework (CVPR 2023) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Zheng_Open-Category_Human-Object_Interaction_Pre-Training_via_Language_Modeling_Framework_CVPR_2023_paper.html)]

* Being Comes from Not-being: Open-vocabulary Text-to-Motion Generation with Wordless Training (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2210.15929)]

* OVTrack: Open-Vocabulary Multiple Object Tracking (CVPR 2023) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Li_OVTrack_Open-Vocabulary_Multiple_Object_Tracking_CVPR_2023_paper.html)]
#### ICLR
* The Devil is in the Wrongly-classified Samples: Towards Unified Open-set Recognition (ICLR 2023) 
[[Paper](https://openreview.net/pdf?id=xLr0I_xYGAs)]<br>
*Datasets: CIFAR100, LSUN, MiTv2, UCF101, HMDB51*<br>
*Task: Image and Video Classification*
<!--#### NeurIPS
#### ICCV-->
#### ICML

* Open-VCLIP: Transforming CLIP to an Open-vocabulary Video Model via Interpolated Weight Optimization (ICML 2023) 
[[Paper](https://arxiv.org/abs/2302.00624)]

<!--#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw-->
#### Arxiv & Others

* Transforming CLIP to an Open-vocabulary Video Model via Interpolated Weight Optimization (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2302.00624)]

* TagCLIP: Improving Discrimination Ability of Open-Vocabulary Semantic Segmentation (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2304.07547)]

* MVP-SEG: Multi-View Prompt Learning for Open-Vocabulary Semantic Segmentation (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2304.06957)]

* Segment Everything Everywhere All at Once (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2304.06718)]

* Towards Open-Vocabulary Video Instance Segmentation (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2304.01715)]

* CLIP Surgery for Better Explainability with Enhancement in Open-Vocabulary Tasks (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2304.05653)]

* Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary Visual Recognition (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2304.04704)]

* V3Det: Vast Vocabulary Visual Detection Dataset (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2304.03752)]

* Token Merging for Fast Stable Diffusion (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.17604)]

* Going Beyond Nouns With Vision & Language Models Using Synthetic Data (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.17590)]

* MaMMUT: A Simple Architecture for Joint Learning for MultiModal Tasks (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.16839)]

* ZBS: Zero-shot Background Subtraction via Instance-level Background Modeling and Foreground Selection (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2303.14679)]

* Prompt-Guided Transformers for End-to-End Open-Vocabulary Object Detection (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.14386)]

* Three ways to improve feature alignment for open vocabulary detection (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.13518)]

* Zero-guidance Segmentation Using Zero Segment Labels (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.13396)]

* Open-Vocabulary Object Detection using Pseudo Caption Labels (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.13040)]

* Uni-Fusion: Universal Continuous Mapping (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.12678)]
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2022 Papers
<!-- #### CVPR
#### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw-->
#### Arxiv & Others

* Open-Vocabulary Temporal Action Detection with Off-the-Shelf Image-Text Features (Arxiv 2022) 
[[Paper](https://arxiv.org/abs/2212.10596)]

<!----------------------------------------------------------------------------------------------------------------------------------------------->
<!--### 2021 Papers
 #### CVPR
#### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->

<!----------------------------------------------------------------------------------------------------------------------------------------------->
## Fine Grained Videos
<!----------------------------------------------------------------------------------------------------------------------------------------------->

### 2023 Papers
#### CVPR
* On the Difficulty of Unpaired Infrared-to-Visible Video Translation: Fine-Grained Content-Rich Patches Transfer (CVPR 2023) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Yu_On_the_Difficulty_of_Unpaired_Infrared-to-Visible_Video_Translation_Fine-Grained_Content-Rich_CVPR_2023_paper.html)]

* ANetQA: A Large-scale Benchmark for Fine-grained Compositional Reasoning over Untrimmed Videos (CVPR 2023) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Yu_ANetQA_A_Large-Scale_Benchmark_for_Fine-Grained_Compositional_Reasoning_Over_Untrimmed_CVPR_2023_paper.html)]

* MELTR: Meta Loss Transformer for Learning to Fine-tune Video Foundation Models (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2303.13009)]

* Modeling Video as Stochastic Processes for Fine-Grained Video Representation Learning (CVPR 2023) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Modeling_Video_As_Stochastic_Processes_for_Fine-Grained_Video_Representation_Learning_CVPR_2023_paper.html)]

* Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos (CVPR 2023) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Gupta_Class_Prototypes_Based_Contrastive_Learning_for_Classifying_Multi-Label_and_Fine-Grained_CVPR_2023_paper.html)]

* Progressive Disentangled Representation Learning for Fine-Grained Controllable Talking Head Synthesis (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2211.14506)]

* Focus On Details: Online Multi-object Tracking with Diverse Fine-grained Representation (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2302.14589)]

* Fine-grained Audible Video Description (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2303.15616)]
<!-- #### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw-->
#### WACV
* Fine-Grained Activities of People Worldwide (WACV 2023) 
[[Paper](https://openaccess.thecvf.com/content/WACV2023/papers/Byrne_Fine-Grained_Activities_of_People_Worldwide_WACV_2023_paper.pdf)]
[[Code](https://visym.github.io/cap)]<br>
*Datasets: Consented Activities of People (CAP)*<br>
*Task: Action Recognition*

* Fine-Grained Affordance Annotation for Egocentric Hand-Object Interaction Videos (WACV 2023) 
[[Paper](https://openaccess.thecvf.com/content/WACV2023/papers/Yu_Fine-Grained_Affordance_Annotation_for_Egocentric_Hand-Object_Interaction_Videos_WACV_2023_paper.pdf)]<br>
*Datasets:  EPIC-KITCHENS*<br>
*Task: Action Recognition*
<!--#### IJCV
#### BMVC
#### ICCw-->
#### Arxiv & Others
* Hand Guided High Resolution Feature Enhancement for Fine-Grained Atomic Action Segmentation Within Complex Human Assemblies (WACVw 2023) 
[[Paper](http://arxiv.org/abs/2211.13694)]

* A Transformer-Based Late-Fusion Mechanism for Fine-Grained Object Recognition in Videos (WACVw 2023) 
[[Paper](https://openaccess.thecvf.com/content/WACV2023W/RWS/papers/Koch_A_Transformer-Based_Late-Fusion_Mechanism_for_Fine-Grained_Object_Recognition_in_Videos_WACVW_2023_paper.pdf)]

* Simplifying Open-Set Video Domain Adaptation with Contrastive Learning (CVIU 2023 under review) 
[[Paper](https://arxiv.org/abs/2301.03322)]
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2022 Papers
#### CVPR

* FineDiving: A Fine-Grained Dataset for Procedure-Aware Action Quality Assessment (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_FineDiving_A_Fine-Grained_Dataset_for_Procedure-Aware_Action_Quality_Assessment_CVPR_2022_paper.pdf)]
[[Code](https://github.com/xujinglin/FineDiving)]<br>
*Datasets: FineDiving*<br>
*Task: Action Quality Assessment*

* Fine-Grained Temporal Contrastive Learning for Weakly-Supervised Temporal Action Localization (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_Fine-Grained_Temporal_Contrastive_Learning_for_Weakly-Supervised_Temporal_Action_Localization_CVPR_2022_paper.pdf)]
[[Code](https://github.com/MengyuanChen21/CVPR2022-FTCL)]<br>
*Datasets: THUMOS14; ActivityNet1.3*<br>
*Task: Temporal Action Localization*

* How Do You Do It? Fine-Grained Action Understanding With Pseudo-Adverbs (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Doughty_How_Do_You_Do_It_Fine-Grained_Action_Understanding_With_Pseudo-Adverbs_CVPR_2022_paper.pdf)]
[[Code](https://github.com/hazeld/PseudoAdverbs)]<br>
*Datasets: VATEX Adverbs, ActivityNet Adverbs and MSR-VTT Adverbs*<br>
*Task: Adverb Recognition*

* EMScore: Evaluating Video Captioning via Coarse-Grained and Fine-Grained Embedding Matching (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_EMScore_Evaluating_Video_Captioning_via_Coarse-Grained_and_Fine-Grained_Embedding_Matching_CVPR_2022_paper.pdf)]
[[Code](https://github.com/shiyaya/emscore)]<br>
*Datasets: VATEX-EVAL; ActivityNet-FOIL*<br>
*Task: Video Captioning*
<!-- #### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access-->
#### ECCV
* Dynamic Spatio-Temporal Specialization Learning for Fine-Grained Action Recognition (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136640381.pdf)]<br>
*Datasets: Diving48*<br>
*Task: Action Recognition*

* Exploring Fine-Grained Audiovisual Categorization with the SSW60 Dataset (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136680262.pdf)]
[[Code](https://github.com/visipedia/ssw60)]<br>
*Datasets: SSW60*<br>
*Task: Action Recognition*

* Weakly-Supervised Temporal Action Detection for Fine-Grained Videos with Hierarchical Atomic Actions (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136700562.pdf)]
[[Code](https://github.com/lizhi1104/HAAN.git)]<br>
*Datasets: FineAction; FineGym*<br>
*Task: Action Recognition*

* Semantic-Aware Fine-Grained Correspondence (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136910093.pdf)]<br>
*Datasets: DAVIS-2017; JHMDB; Video Instance Parsing (VIP)*<br>
*Task: Video Object Segmentation, Human Pose Tracking, Human Part Tracking*

* Spotting Temporally Precise, Fine-Grained Events in Video (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136950033.pdf)]<br>
*Datasets: Tennis, Figure Skating, FineDiving, and Fine-Gym*<br>
*Task: Temporally Precise Spotting*

* Fine-Grained Egocentric Hand-Object Segmentation: Dataset, Model, and Applications (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136890125.pdf)]
[[Code](https://github.com/owenzlz/EgoHOS)]<br>
*Datasets: EPIC-KITCHENS; Ego4d; THU-READ; Escape Room*<br>
*Task: Semantic Segmentation*
<!-- #### AAAI
#### TPAMI-->
#### CVPRw
* FenceNet: Fine-Grained Footwork Recognition in Fencing (CVPRw 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022W/CVSports/papers/Zhu_FenceNet_Fine-Grained_Footwork_Recognition_in_Fencing_CVPRW_2022_paper.pdf)]<br>
*Datasets:  FFD a publicly available fencing dataset*<br>
*Task: Action Recognition*
<!--#### WACV
#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2021 Papers
#### CVPR

* Fine-Grained Shape-Appearance Mutual Learning for Cloth-Changing Person Re-Identification (CVPR 2021) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Hong_Fine-Grained_Shape-Appearance_Mutual_Learning_for_Cloth-Changing_Person_Re-Identification_CVPR_2021_paper.pdf)]


* Temporal Query Networks for Fine-Grained Video Understanding (CVPR 2021) 
[[Paper](http://arxiv.org/abs/2104.09496)]

* GLAVNet: Global-Local Audio-Visual Cues for Fine-Grained Material Recognition (CVPR 2021) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Shi_GLAVNet_Global-Local_Audio-Visual_Cues_for_Fine-Grained_Material_Recognition_CVPR_2021_paper.pdf)]


<!--#### ICLR
#### NeurIPS-->
#### ICCV

* Counterfactual Attention Learning for Fine-Grained Visual Categorization and Re-Identification (ICCV 2021) 
[[Paper](http://arxiv.org/abs/2108.08728)]

* Video Pose Distillation for Few-Shot, Fine-Grained Sports Action Recognition (ICCV 2021) 
[[Paper](http://arxiv.org/abs/2109.01305)]

* FuseFormer: Fusing Fine-Grained Information in Transformers for Video Inpainting (ICCV 2021) 
[[Paper](http://arxiv.org/abs/2109.02974)]

<!--#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->

<!----------------------------------------------------------------------------------------------------------------------------------------------->
### Older Papers
* FineGym: A Hierarchical Video Dataset for Fine-Grained Action Understanding (CVPR 2020) 
[[Paper](http://arxiv.org/abs/2004.06704)]

* Multi-Modal Domain Adaptation for Fine-Grained Action Recognition (CVPR 2020) 
[[Paper](http://arxiv.org/abs/2001.09691)]

* Revisiting Pose-Normalization for Fine-Grained Few-Shot Recognition (CVPR 2020) 
[[Paper](http://arxiv.org/abs/2004.00705)]

* Fine-Grained Video-Text Retrieval With Hierarchical Graph Reasoning (CVPR 2020) 
[[Paper](http://arxiv.org/abs/2003.00392)]

* Stochastic Fine-grained Labeling of Multi-state Sign Glosses for Continuous Sign Language Recognition (ECCV 2020) 
[[Paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123610171.pdf)]

* Fine-Grained Motion Representation For Template-Free Visual Tracking (WACV 2020) 
[[Paper](https://openaccess.thecvf.com/content_WACV_2020/papers/Shuang_Fine-Grained_Motion_Representation_For_Template-Free_Visual_Tracking_WACV_2020_paper.pdf)]

* WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose (BMVC 2020) 
[[Paper](https://www.bmvc2020-conference.com/assets/papers/0907.pdf)]

* Yoga-82: A New Dataset for Fine-Grained Classification of Human Poses (CVPRw 2020) 
[[Paper](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w70/Verma_Yoga-82_A_New_Dataset_for_Fine-Grained_Classification_of_Human_Poses_CVPRW_2020_paper.pdf)]

* Fine-Grained Pointing Recognition for Natural Drone Guidance (CVPRw 2020) 
[[Paper](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w70/Barbed_Fine-Grained_Pointing_Recognition_for_Natural_Drone_Guidance_CVPRW_2020_paper.pdf)]

* Local Temporal Bilinear Pooling for Fine-Grained Action Parsing (CVPR 2019) 
[[Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Local_Temporal_Bilinear_Pooling_for_Fine-Grained_Action_Parsing_CVPR_2019_paper.pdf)]

* Drive&Act: A Multi-Modal Dataset for Fine-Grained Driver Behavior Recognition in Autonomous Vehicles (ICCV 2019) 
[[Paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Martin_DriveAct_A_Multi-Modal_Dataset_for_Fine-Grained_Driver_Behavior_Recognition_in_ICCV_2019_paper.pdf)]

* Fine-Grained Action Retrieval Through Multiple Parts-of-Speech Embeddings (ICCV 2019) 
[[Paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Wray_Fine-Grained_Action_Retrieval_Through_Multiple_Parts-of-Speech_Embeddings_ICCV_2019_paper.pdf)]

* Learning Motion in Feature Space: Locally-Consistent Deformable Convolution Networks for Fine-Grained Action Detection (ICCV 2019) 
[[Paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Mac_Learning_Motion_in_Feature_Space_Locally-Consistent_Deformable_Convolution_Networks_for_ICCV_2019_paper.pdf)]

* ViSiL: Fine-Grained Spatio-Temporal Video Similarity Learning (ICCV 2019) 
[[Paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Kordopatis-Zilos_ViSiL_Fine-Grained_Spatio-Temporal_Video_Similarity_Learning_ICCV_2019_paper.pdf)]

* Fine-Grained Visual Dribbling Style Analysis for Soccer Videos With Augmented Dribble Energy Image (CVPRw 2019) 
[[Paper](https://openaccess.thecvf.com/content_CVPRW_2019/papers/CVSports/Li_Fine-Grained_Visual_Dribbling_Style_Analysis_for_Soccer_Videos_With_Augmented_CVPRW_2019_paper.pdf)]

* Anticipation of Human Actions With Pose-Based Fine-Grained Representations (CVPRw 2019) 
[[Paper](https://openaccess.thecvf.com/content_CVPRW_2019/papers/Precognition/Agethen_Anticipation_of_Human_Actions_With_Pose-Based_Fine-Grained_Representations_CVPRW_2019_paper.pdf)]

* Fine-Grained Video Captioning for Sports Narrative (CVPR 2018) 
[[Paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_Fine-Grained_Video_Captioning_CVPR_2018_paper.pdf)]

* Where Will They Go? Predicting Fine-Grained Adversarial Multi-Agent Motion using Conditional Variational Autoencoders (ECCV 2018) 
[[Paper](https://www.ecva.net/papers/eccv_2018/papers_ECCV/papers/Panna_Felsen_Where_Will_They_ECCV_2018_paper.pdf)]

* Fine-grained Video Categorization with Redundancy Reduction Attention (ECCV 2018) 
[[Paper](https://www.ecva.net/papers/eccv_2018/papers_ECCV/papers/Chen_Zhu_Fine-grained_Video_Categorization_ECCV_2018_paper.pdf)]

* Fine-Grained Head Pose Estimation Without Keypoints (CVPRw 2018) 
[[Paper](http://arxiv.org/abs/1710.00925)]

* Fine-Grained Activity Recognition in Baseball Videos (CVPRw 2018) 
[[Paper](http://arxiv.org/abs/1804.03247)]

<!----------------------------------------------------------------------------------------------------------------------------------------------->
## Long Tail Videos
<!----------------------------------------------------------------------------------------------------------------------------------------------->

### 2023 Papers
#### CVPR
* Use Your Head: Improving Long-Tail Video Recognition (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2304.01143)]

* FEND: A Future Enhanced Distribution-Aware Contrastive Learning Framework For Long-tail Trajectory Prediction (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2303.16574)]

<!--#### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->
<!----------------------------------------------------------------------------------------------------------------------------------------------->
<!--### 2022 Papers
#### CVPR
#### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2021 Papers
<!--#### CVPR
#### ICLR
#### NeurIPS-->
#### ICCV
* VideoLT: Large-Scale Long-Tailed Video Recognition (ICCV 2021) 
[[Paper](http://arxiv.org/abs/2105.02668)]

* On Exposing the Challenging Long Tail in Future Prediction of Traffic Actors (ICCV 2021) 
[[Paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Makansi_On_Exposing_the_Challenging_Long_Tail_in_Future_Prediction_of_ICCV_2021_paper.pdf)]
<!--#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->

<!----------------------------------------------------------------------------------------------------------------------------------------------->
## Anomaly Detection Videos
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2023 Papers
<!-- #### CVPR
#### ICLR
#### NeurIPS-->
#### ICCV
* Multimodal Motion Conditioned Diffusion Model for Skeleton-based Video Anomaly Detection (ICCV 2023) 
[[Paper](https://arxiv.org/abs/2307.07205)]<br>

<!--#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw-->
#### WACV
* DyAnNet: A Scene Dynamicity Guided Self-Trained Video Anomaly Detection Network (WACV 2023) 
[[Paper](http://arxiv.org/abs/2211.00882)]<br>
*Datasets: UCF-Crime, CCTV-Fights, UBI-Fights*

* Cross-Domain Video Anomaly Detection Without Target Domain Adaptation (WACV 2023) 
[[Paper](http://arxiv.org/abs/2212.07010)]<br>
*Datasets: SHTdc, SHT and Ped2, HMDB, UCF101*

* Bi-Directional Frame Interpolation for Unsupervised Video Anomaly Detection (WACV 2023) 
[[Paper](https://openaccess.thecvf.com/content/WACV2023/papers/Deng_Bi-Directional_Frame_Interpolation_for_Unsupervised_Video_Anomaly_Detection_WACV_2023_paper.pdf)]<br>
*Datasets: UCSD Ped2, CUHK Avenue, ShanghaiTech Campus*

* Towards Interpretable Video Anomaly Detection (WACV 2023) 
[[Paper](https://openaccess.thecvf.com/content/WACV2023/papers/Doshi_Towards_Interpretable_Video_Anomaly_Detection_WACV_2023_paper.pdf)]<br>
*Datasets: CUHK Avenue, ShanghaiTech Campus*

* Normality Guided Multiple Instance Learning for Weakly Supervised Video Anomaly Detection (WACV 2023) 
[[Paper](https://openaccess.thecvf.com/content/WACV2023/papers/Park_Normality_Guided_Multiple_Instance_Learning_for_Weakly_Supervised_Video_Anomaly_WACV_2023_paper.pdf)]<br>
*Datasets: ShanghaiTech, UCF-Crime, XD-Violence*


<!--#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2022 Papers
#### CVPR
* UBnormal: New Benchmark for Supervised Open-Set Video Anomaly Detection (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Acsintoae_UBnormal_New_Benchmark_for_Supervised_Open-Set_Video_Anomaly_Detection_CVPR_2022_paper.pdf)]
[[Code](https://github.com/lilygeorgescu/UBnormal)]<br>
*Datasets: UBnormal, CHUK, Avenue, Shang-hai Tech*

* Deep Anomaly Discovery From Unlabeled Videos via Normality Advantage and Self-Paced Refinement (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Deep_Anomaly_Discovery_From_Unlabeled_Videos_via_Normality_Advantage_and_CVPR_2022_paper.pdf)]
[[Code](https://github.com/lilygeorgescu/AED-SSMTL)]<br>
*Datasets: UCS-Dped1/UCSDped2, Avenue and  ShanghaiTech*

* Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Ristea_Self-Supervised_Predictive_Convolutional_Attentive_Block_for_Anomaly_Detection_CVPR_2022_paper.pdf)]
[[Code](https://github.com/ristea/sspcab)]<br>
*Datasets: MVTec AD, Avenue and  ShanghaiTech*

* Anomaly Detection via Reverse Distillation From One-Class Embedding (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_Anomaly_Detection_via_Reverse_Distillation_From_One-Class_Embedding_CVPR_2022_paper.pdf)]<br>
*Datasets: MVTec; MNIST, FashionMNIST and CIFAR10*<br>

* Bayesian Nonparametric Submodular Video Partition for Robust Anomaly Detection (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Sapkota_Bayesian_Nonparametric_Submodular_Video_Partition_for_Robust_Anomaly_Detection_CVPR_2022_paper.pdf)]<br>
*Datasets: ShanghaiTech, Avenue, UCF-Crime*

* Towards Total Recall in Industrial Anomaly Detection (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Roth_Towards_Total_Recall_in_Industrial_Anomaly_Detection_CVPR_2022_paper.pdf)]
[[Code](https://github.com/amazon-science/patchcore-inspection)]<br>
*Datasets: MVTec; Magnetic Tile Defects (MTD); Mini Shanghai Tech Campus(mSTC)*


* Generative Cooperative Learning for Unsupervised Video Anomaly Detection (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Zaheer_Generative_Cooperative_Learning_for_Unsupervised_Video_Anomaly_Detection_CVPR_2022_paper.pdf)]
[[Code](https://github.com/amazon-science/patchcore-inspection)]<br>
*Datasets: UCF-Crime (UCFC); ShanghaiTech*

<!-- #### ICLR
#### NeurIPS
#### ICCV-->
#### ICML

* Latent Outlier Exposure for Anomaly Detection with Contaminated Data (ICML 2022) 
[[Paper](https://arxiv.org/abs/2202.08088)]
[[Code](https://github.com/boschresearch/LatentOE-AD.git)]<br>
*Datasets:  CIFAR-10, Fashion-MNIST, MVTEC, 30 tabular data sets, UCSD Peds1*<br>

<!--#### IEEE-Access-->
#### ECCV
* Towards Open Set Video Anomaly Detection (ECCV 2022) 
[[Paper](https://arxiv.org/pdf/2208.11113v1.pdf)]<br>
*Datasets: XD Violence, UCF Crime, ShanghaiTech Campus*

* Scale-Aware Spatio-Temporal Relation Learning for Video Anomaly Detection (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136640328.pdf)]
[[Code](https://github.com/nutuniv/SSRL)]<br>
*Datasets: UCF-Crime (UCFC); ShanghaiTech*

* Dynamic Local Aggregation Network with Adaptive Clusterer for Anomaly Detection (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136640398.pdf)]
[[Code](https://github.com/Beyond-Zw/DLAN-AC)]<br>
*Datasets: CUHK Avenue; UCSD Ped2; ShanghaiTech*

* Video Anomaly Detection by Solving Decoupled Spatio-Temporal Jigsaw Puzzles (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136700490.pdf)]<br>
*Datasets: CUHK Avenue; UCSD Ped2; ShanghaiTech*

* Self-Supervised Sparse Representation for Video Anomaly Detection (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136730727.pdf)]
[[Code](https://github.com/louisYen/S3R)]<br>
*Datasets: ShanghaiTech, UCF-Crime, and XD-Violence*

* Registration Based Few-Shot Anomaly Detection (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136840300.pdf)]
[[Code](https://github.com/MediaBrain-SJTU/RegAD)]<br>
*Datasets: MVTec; MPDD*

* DenseHybrid: Hybrid Anomaly Detection for Dense Open-set Recognition (ECCV 2022) 
[[Paper](https://arxiv.org/pdf/2207.02606v1.pdf)]
[[Code](https://github.com/matejgrcic/DenseHybrid)]<br>
*Datasets: Fishyscapes, SegmentMeIfYouCan (SMIYC), StreetHazards*

<!--#### AAAI
#### TPAMI-->
#### CVPRw
* Unsupervised Anomaly Detection From Time-of-Flight Depth Images (CVPRw 2022) 
[[Paper](https://arxiv.org/abs/2203.01052v2)]<br>
*Datasets: TIMo*<br>

* Adversarial Machine Learning Attacks Against Video Anomaly Detection Systems (CVPRw 2022) 
[[Paper](https://arxiv.org/abs/2204.03141v1)]<br>
*Datasets: CUHK Avenue, the ShanghaiTech Campus*<br>

* Anomaly Detection in Autonomous Driving: A Survey (CVPRw 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022W/WAD/papers/Bogdoll_Anomaly_Detection_in_Autonomous_Driving_A_Survey_CVPRW_2022_paper.pdf)]

#### WACV
* A Modular and Unified Framework for Detecting and Localizing Video Anomalies (WACV 2022) 
[[Paper](http://arxiv.org/abs/2103.11299)]<br>
*Datasets: CUHK Avenue, UCSD Ped2, ShanghaiTech Campus, UR fall*<br>

* FastAno: Fast Anomaly Detection via Spatio-Temporal Patch Transformation (WACV 2022) 
[[Paper](http://arxiv.org/abs/2106.08613)]<br>
*Datasets: CUHK Avenue, UCSD Ped2, ShanghaiTech Campus*<br>

* Multi-Branch Neural Networks for Video Anomaly Detection in Adverse Lighting and Weather Conditions (WACV 2022) 
[[Paper](https://openaccess.thecvf.com/content/WACV2022/papers/Leroux_Multi-Branch_Neural_Networks_for_Video_Anomaly_Detection_in_Adverse_Lighting_WACV_2022_paper.pdf)]
[[Code](https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library)]<br>
*Datasets: CUHK Avenue (Augmented)*<br>

* Discrete Neural Representations for Explainable Anomaly Detection (WACV 2022) 
[[Paper](http://arxiv.org/abs/2112.05585)]
[[Code](http://jjcvision.com/projects/vqunet_anomally_detection.html)]<br>
*Datasets: CUHK Avenue, UCSD Ped2, X-MAN*<br>

* Rethinking Video Anomaly Detection - A Continual Learning Approach (WACV 2022) 
[[Paper](https://openaccess.thecvf.com/content/WACV2022/papers/Doshi_Rethinking_Video_Anomaly_Detection_-_A_Continual_Learning_Approach_WACV_2022_paper.pdf)]<br>
*Datasets: NOLA*<br>


<!--#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2021 Papers
<!-- #### CVPR
#### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI-->
#### CVPRw
* Box-Level Tube Tracking and Refinement for Vehicles Anomaly Detection (CVPRw 2021) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2021W/AICity/papers/Wu_Box-Level_Tube_Tracking_and_Refinement_for_Vehicles_Anomaly_Detection_CVPRW_2021_paper.pdf)]

* Dual-Modality Vehicle Anomaly Detection via Bilateral Trajectory Tracing (CVPRw 2021) 
[[Paper](http://arxiv.org/abs/2106.05003)]

* A Vision-Based System for Traffic Anomaly Detection Using Deep Learning and Decision Trees (CVPRw 2021) 
[[Paper](http://arxiv.org/abs/2104.06856)]

* Good Practices and a Strong Baseline for Traffic Anomaly Detection (CVPRw 2021) 
[[Paper](http://arxiv.org/abs/2105.03827)]

* An Efficient Approach for Anomaly Detection in Traffic Videos (CVPRw 2021) 
[[Paper](http://arxiv.org/abs/2104.09758)]


* Spacecraft Time-Series Anomaly Detection Using Transfer Learning (CVPRw 2021) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/papers/Baireddy_Spacecraft_Time-Series_Anomaly_Detection_Using_Transfer_Learning_CVPRW_2021_paper.pdf)]
<!--#### WACV
#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->

<!----------------------------------------------------------------------------------------------------------------------------------------------->
### Older Papers

* Multi-Granularity Tracking With Modularlized Components for Unsupervised Vehicles Anomaly Detection (CVPRw 2020) 
[[Paper](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w35/Li_Multi-Granularity_Tracking_With_Modularlized_Components_for_Unsupervised_Vehicles_Anomaly_Detection_CVPRW_2020_paper.pdf)]

* Fractional Data Distillation Model for Anomaly Detection in Traffic Videos (CVPRw 2020) 
[[Paper](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w35/Shine_Fractional_Data_Distillation_Model_for_Anomaly_Detection_in_Traffic_Videos_CVPRW_2020_paper.pdf)]

* Towards Real-Time Systems for Vehicle Re-Identification, Multi-Camera Tracking, and Anomaly Detection (CVPRw 2020) 
[[Paper](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w35/Peri_Towards_Real-Time_Systems_for_Vehicle_Re-Identification_Multi-Camera_Tracking_and_Anomaly_CVPRW_2020_paper.pdf)]

* Fast Unsupervised Anomaly Detection in Traffic Videos (CVPRw 2020) 
[[Paper](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w35/Doshi_Fast_Unsupervised_Anomaly_Detection_in_Traffic_Videos_CVPRW_2020_paper.pdf)]

* Continual Learning for Anomaly Detection in Surveillance Videos (CVPRw 2020) 
[[Paper](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w15/Doshi_Continual_Learning_for_Anomaly_Detection_in_Surveillance_Videos_CVPRW_2020_paper.pdf)]

* Any-Shot Sequential Anomaly Detection in Surveillance Videos (CVPRw 2020) 
[[Paper](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w54/Doshi_Any-Shot_Sequential_Anomaly_Detection_in_Surveillance_Videos_CVPRW_2020_paper.pdf)]


* Challenges in Time-Stamp Aware Anomaly Detection in Traffic Videos (CVPRw 2019) 
[[Paper](https://openaccess.thecvf.com/content_CVPRW_2019/papers/AI%20City/Biradar_Challenges_in_Time-Stamp_Aware_Anomaly_Detection_in_Traffic_Videos_CVPRW_2019_paper.pdf)]

* Traffic Anomaly Detection via Perspective Map based on Spatial-temporal Information Matrix (CVPRw 2019) 
[[Paper](https://openaccess.thecvf.com/content_CVPRW_2019/papers/AI%20City/Bai_Traffic_Anomaly_Detection_via_Perspective_Map_based_on_Spatial-temporal_Information_CVPRW_2019_paper.pdf)]

* Unsupervised Traffic Anomaly Detection Using Trajectories (CVPRw 2019) 
[[Paper](https://openaccess.thecvf.com/content_CVPRW_2019/papers/AI%20City/Zhao_Unsupervised_Traffic_Anomaly_Detection_Using_Trajectories_CVPRW_2019_paper.pdf)]

* Attention Driven Vehicle Re-identification and Unsupervised Anomaly Detection for Traffic Understanding (CVPRw 2019) 
[[Paper](https://openaccess.thecvf.com/content_CVPRW_2019/papers/AI%20City/Khorramshahi_Attention_Driven_Vehicle_Re-identification_and_Unsupervised_Anomaly_Detection_for_Traffic_CVPRW_2019_paper.pdf)]

* A Comparative Study of Faster R-CNN Models for Anomaly Detection in 2019 AI City Challenge (CVPRw 2019) 
[[Paper](https://openaccess.thecvf.com/content_CVPRW_2019/papers/AI%20City/Shine_A_Comparative_Study_of_Faster_R-CNN_Models_for_Anomaly_Detection_CVPRW_2019_paper.pdf)]

* Anomaly Candidate Identification and Starting Time Estimation of Vehicles from Traffic Videos (CVPRw 2019) 
[[Paper](https://openaccess.thecvf.com/content_CVPRW_2019/papers/AI%20City/Wang_Anomaly_Candidate_Identification_and_Starting_Time_Estimation_of_Vehicles_from_CVPRW_2019_paper.pdf)]

* Hybrid Deep Network for Anomaly Detection (BMVC 2019) 
[[Paper](https://bmvc2019.org/wp-content/papers/0726.html)]<br>
*Datasets: CUHK Avenue, UCSD Ped2, Belleview, Traffic-Train*<br>

* Motion-Aware Feature for Improved Video Anomaly Detection (BMVC 2019) 
[[Paper](https://bmvc2019.org/wp-content/papers/0129.html)]<br>
*Datasets: UCF Crime*<br>

* Adversarially Learned One-Class Classifier for Novelty Detection (CVPR 2018) 
[[Paper](http://arxiv.org/abs/1802.09088)]<br>
*Datasets: MNIST, Caltech-256, UCSD Ped2*<br>
*Task: Image Classification, Anomaly Detection*

* Real-World Anomaly Detection in Surveillance Videos (CVPR 2018) 
[[Paper](http://arxiv.org/abs/1801.04264)]
[[Code](http://crcv.ucf.edu/projects/real-world/)]<br>
*Datasets: Real-world Surveillance Videos*<br>

* Future Frame Prediction for Anomaly Detection â€“ A New Baseline (CVPR 2018) 
[[Paper](https://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Future_Frame_Prediction_CVPR_2018_paper.html)]
[[Code](https://github.com/StevenLiuWen/ano_pred_cvpr2018)]<br>
*Datasets: CUHK, Avenue, UCSD Ped1, UCSD Ped2, ShanghaiTech, Paper's toy dataset*<br>

* Unsupervised Anomaly Detection for Traffic Surveillance Based on Background Modeling (CVPRw 2018) 
[[Paper](https://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w3/Wei_Unsupervised_Anomaly_Detection_CVPR_2018_paper.pdf)]

* Dual-Mode Vehicle Motion Pattern Learning for High Performance Road Traffic Anomaly Detection (CVPRw 2018) 
[[Paper](https://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w3/Xu_Dual-Mode_Vehicle_Motion_CVPR_2018_paper.pdf)]

<!----------------------------------------------------------------------------------------------------------------------------------------------->
## Novelty Detection
<!----------------------------------------------------------------------------------------------------------------------------------------------->
<!--### 2023 Papers
#### CVPR
#### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->
<!----------------------------------------------------------------------------------------------------------------------------------------------->
<!--### 2022 Papers
#### CVPR
#### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access-->
#### ECCV
* incDFM: Incremental Deep Feature Modeling for Continual Novelty Detection (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136850581.pdf)]<br>
*Datasets: 1.CIFAR-10 (10 classes), 2. CIFAR-100 (super-classlevel, 20 classes), 3. EMNIST (26 classes) and 4. iNaturalist21 (phylumlevel, 9 classes)*<br>
*Task: Image Classification*
<!--#### AAAI
#### TPAMI
#### CVPRw-->
#### WACV
* One-Class Learned Encoder-Decoder Network With Adversarial Context Masking for Novelty Detection (WACV 2022) 
[[Paper](https://openaccess.thecvf.com/content/WACV2022/papers/Jewell_One-Class_Learned_Encoder-Decoder_Network_With_Adversarial_Context_Masking_for_Novelty_WACV_2022_paper.pdf)]
[[Code](https://github.com/jewelltaylor/OLED)]<br>
*Datasets: MNIST, CIFAR-10, UCSD*<br>
*Task: Novelty Detection, Anomaly*

<!--#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->

<!----------------------------------------------------------------------------------------------------------------------------------------------->

### 2021 Papers
#### CVPR
* Learning Deep Classifiers Consistent With Fine-Grained Novelty Detection (CVPR 2021) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Cheng_Learning_Deep_Classifiers_Consistent_With_Fine-Grained_Novelty_Detection_CVPR_2021_paper.pdf)]<br>
*Datasets: small- and large-scale FGVC*<br>
*Task: Novelty Detection*

<!--#### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access
#### ECCV-->
#### AAAI

* A Unifying Framework for Formal Theories of Novelty:Framework, Examples and Discussion (AAAI 2021) 
[[Paper](https://arxiv.org/abs/2012.06957)] 

<!--#### TPAMI
#### CVPRw
#### WACV
#### IJCV-->
#### BMVC

* Multi-Class Novelty Detection with Generated Hard Novel Features (BMVC 2021) 
[[Paper](https://www.bmvc2021-virtualconference.com/assets/papers/0838.pdf)]<br>
*Datasets: Stanford Dogs, Caltech 256, CUB 200, FounderType-200*<br>
*Task: Image Classification*

<!--#### ICCw
#### Arxiv & Others-->

<!----------------------------------------------------------------------------------------------------------------------------------------------->
### Older Papers
<!----------------------------------------------------------------------------------------------------------------------------------------------->
* Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents (NeurIPS 2018) 
[[Paper](https://papers.nips.cc/paper/2018/hash/b1301141feffabac455e1f90a7de2054-Abstract.html)]<br>
*Datasets: OpenAI Gym*<br>
*Task: Reinforcement Learning*

* Multivariate Triangular Quantile Maps for Novelty Detection (NeurIPS 2019) 
[[Paper](https://papers.nips.cc/paper/2019/hash/6244b2ba957c48bc64582cf2bcec3d04-Abstract.html)]
[[Code](https://github.com/GinGinWang/MTQ)]<br>
*Datasets: MNIST and Fashion-MNIST, KDDCUP and Thyroid*<br>
*Task: Image Classification*

* Multi-class Novelty Detection Using Mix-up Technique (WACV 2020) 
[[Paper](https://openaccess.thecvf.com/content_WACV_2020/papers/Bhattacharjee_Multi-class_Novelty_Detection_Using_Mix-up_Technique_WACV_2020_paper.pdf)]<br>
*Datasets: Caltech 256 and Stanford Dogs*<br>
*Task: Image Classification*

* Hierarchical Novelty Detection for Visual Object Recognition (CVPR 2018) 
[[Paper](http://arxiv.org/abs/1804.00722)]<br>
*Datasets: ImageNet, AwA2, CUB*<br>
*Task: Image Classification*

* Adversarially Learned One-Class Classifier for Novelty Detection (CVPR 2018) 
[[Paper](http://arxiv.org/abs/1802.09088)]<br>
*Datasets: MNIST, Caltech-256, UCSD Ped2*<br>
*Task: Image Classification, Anomaly Detection*

* Multiple Class Novelty Detection Under Data Distribution Shift (ECCV 2020) 
[[Paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123520426.pdf)]<br>
*Datasets: SVHN, MNIST and USPS, Office-31*<br>
*Task: Image Classification*

* Utilizing Patch-level Category Activation Patterns for Multiple Class Novelty Detection (ECCV 2020) 
[[Paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123550426.pdf)]<br>
*Datasets: Caltech256, CUB-200, Stanford Dogs and FounderType-200*<br>
*Task: Image Classification*

* Unsupervised and Semi-supervised Novelty Detection using Variational Autoencoders in Opportunistic Science Missions (BMVC 2020) 
[[Paper](https://www.bmvc2020-conference.com/assets/papers/0643.pdf)]<br>
*Datasets: Mars novelty detection Mastcam labeled dataset*<br>
*Task: Image Classification*

* Where's Wally Now? Deep Generative and Discriminative Embeddings for Novelty Detection (CVPR 2019) 
[[Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Burlina_Wheres_Wally_Now_Deep_Generative_and_Discriminative_Embeddings_for_Novelty_CVPR_2019_paper.pdf)]<br>
*Datasets: CIFAR-10, IN-125*<br>
*Task: Image Classification*

* Deep Transfer Learning for Multiple Class Novelty Detection (CVPR 2019) 
[[Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Perera_Deep_Transfer_Learning_for_Multiple_Class_Novelty_Detection_CVPR_2019_paper.pdf)]<br>
*Datasets: Caltech256, Caltech-UCSD Birds 200 (CUB 200), Stanford Dogs, FounderType-200*<br>
*Task: Image Classification*


* Latent Space Autoregression for Novelty Detection (CVPR 2019) 
[[Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Abati_Latent_Space_Autoregression_for_Novelty_Detection_CVPR_2019_paper.pdf)]
[[Code](https://github.com/aimagelab/novelty-detection)]<br>
*Datasets: MNIST, CIFAR10, UCSD Ped2 and ShanghaiTech*<br>
*Task: Image Classification, Video Anomaly Detection*


* OCGAN: One-Class Novelty Detection Using GANs With Constrained Latent Representations (CVPR 2019) 
[[Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Perera_OCGAN_One-Class_Novelty_Detection_Using_GANs_With_Constrained_Latent_Representations_CVPR_2019_paper.pdf)]
[[Code](https://github.com/PramuPerera/OCGAN)]<br>
*Datasets: COIL100, fMNIST, MNIST, CIFAR10*<br>
*Task: Image Classification*

* RaPP: Novelty Detection with Reconstruction along Projection Pathway (ICLR 2020) 
[[Paper](https://openreview.net/forum?id=HkgeGeBYDB)]
[[Code](https://drive.google.com/drive/folders/1sknl_i4zmvSsPYZdzYxbg66ZSYDZ_abg?usp=sharing)]<br>
*Datasets: fMNIST, MNIST, MI-F and MI-V, STL, OTTO, SNSR, EOPT, NASA, RARM*<br>
*Task: Image Classification, Anomaly Detection*

* Novelty Detection Via Blurring (ICLR 2020) 
[[Paper](https://openreview.net/forum?id=ByeNra4FDB)]<br>
*Datasets: CIFAR-10, CIFAR-100, CelebA, ImageNet, LSUN, SVHN*<br>
*Task: Image Classification*

<!----------------------------------------------------------------------------------------------------------------------------------------------->
## Other Related Papers
<!----------------------------------------------------------------------------------------------------------------------------------------------->

* Understanding Cross-Domain Few-Shot Learning Based on Domain Similarity and Few-Shot Difficulty	(NeurIPS 2022) 
[[Paper](https://arxiv.org/pdf/2202.01339.pdf)]
[[Code](https://github.com/sungnyun/understanding-cdfsl)]<br>
*Datasets: ImageNet, tieredImageNet, and miniImageNet for source domain similarity to ImageNet: Places,CUB,Cars,Plantae,EuroSAT,CropDisease,ISIC,ChestX*<br>
*Task: Active Learning*

* Self-organization in a perceptual network (Info-max)(IEEE 1988) 
[[Paper](https://ieeexplore.ieee.org/document/36)]<br>


* Mutual Information-Based Temporal Difference Learning for Human Pose Estimation in Video (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2303.08475)]<br>

* Upcycling Models under Domain and Category Shift (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2303.07110)]<br>

* Generative Meta-Adversarial Network for Unseen Object Navigation (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136990295.pdf)]
[[Code](https://github.com/sx-zhang/GMAN.git)]<br>
*Datasets: AI2THOR  and RoboTHOR*<br>
*Task: Object Navigation*


<!----------------------------------------------------------------------------------------------------------------------------------------------->
## Action Recognition Related
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### Surveys
* Vision Transformers for Action Recognition: A Survey (Arxiv 2022) 
[[Paper](https://arxiv.org/abs/2209.05700)]
