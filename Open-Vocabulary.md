## Contents
- [Open Vocabulary](#Open-Vocabulary)
     - [Surveys](#Surveys)
     - [2024 Papers](#2023-Papers)
     - [2023 Papers](#2023-Papers)
     - [2022 Papers](#2022-Papers)
     - [2021 Papers](#2021-Papers)
     - [Older Papers](#Older-Papers)
- [Open Vocabulary-Videos](#Open-Vocabulary-Videos)
     - [2023 Papers](#2023-Papers)
     - [2022 Papers](#2022-Papers)

<!----------------------------------------------------------------------------------------------------------------------------------------------->
## Open Vocabulary
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2024 Papers
#### CVPR
* Open-Vocabulary Segmentation with Semantic-Assisted Calibration (CVPR 2024) 
[[Paper](https://arxiv.org/abs/2312.04089)]

* VideoGrounding-DINO: Towards Open-Vocabulary Spatio-Temporal Video Grounding (CVPR 2024) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Wasim_VideoGrounding-DINO_Towards_Open-Vocabulary_Spatio-Temporal_Video_Grounding_CVPR_2024_paper.pdf)]

* Open-Vocabulary Segmentation with Semantic-Assisted Calibration (CVPR 2024) 
[[Paper](https://arxiv.org/abs/2312.04089)]

* Open3DSG: Open-Vocabulary 3D Scene Graphs from Point Clouds with Queryable Objects and Open-Set Relationships (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2402.12259)]

* Exploring Region-Word Alignment in Built-in Detector for Open-Vocabulary Object Detection (CVPR 2024) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Exploring_Region-Word_Alignment_in_Built-in_Detector_for_Open-Vocabulary_Object_Detection_CVPR_2024_paper.pdf)]

* Open Vocabulary Semantic Scene Sketch Understanding (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2312.12463)]

* USE: Universal Segment Embeddings for Open-Vocabulary Image Segmentation (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2406.05271)]

* Emergent Open-Vocabulary Semantic Segmentation from Off-the-shelf Vision-Language Models (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2311.17095)]

* SHiNe: Semantic Hierarchy Nexus for Open-vocabulary Object Detection (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2405.10053)]

* SED: A Simple Encoder-Decoder for Open-Vocabulary Semantic Segmentation (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2311.15537)]

* Open-Vocabulary 3D Semantic Segmentation with Foundation Models (CVPR 2024) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Jiang_Open-Vocabulary_3D_Semantic_Segmentation_with_Foundation_Models_CVPR_2024_paper.pdf)]

* OVER-NAV: Elevating Iterative Vision-and-Language Navigation with Open-Vocabulary Detection and StructurEd Representation (CVPR 2024) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhao_OVER-NAV_Elevating_Iterative_Vision-and-Language_Navigation_with_Open-Vocabulary_Detection_and_StructurEd_CVPR_2024_paper.pdf)]

* DetCLIPv3: Towards Versatile Generative Open-vocabulary Object Detection (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2404.09216)]

* MaskClustering: View Consensus based Mask Graph Clustering for Open-Vocabulary 3D Instance Segmentation (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2401.07745)]

* Open-Vocabulary Video Anomaly Detection (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2311.07042)]

* CLIP-Driven Open-Vocabulary 3D Scene Graph Generation via Cross-Modality Contrastive Learning (CVPR 2024) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_CLIP-Driven_Open-Vocabulary_3D_Scene_Graph_Generation_via_Cross-Modality_Contrastive_Learning_CVPR_2024_paper.pdf)]

* OMG: Towards Open-vocabulary Motion Generation via Mixture of Controllers (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2312.08985)]

* OpenESS: Event-based Semantic Scene Understanding with Open Vocabularies (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2405.05259)]

* OVFoodSeg: Elevating Open-Vocabulary Food Image Segmentation via Image-Informed Textual Representation (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2404.01409)]

* GOV-NeSF: Generalizable Open-Vocabulary Neural Semantic Fields (CVPR 2024) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_GOV-NeSF_Generalizable_Open-Vocabulary_Neural_Semantic_Fields_CVPR_2024_paper.pdf)]

* Open-Vocabulary Attention Maps with Token Optimization for Semantic Segmentation in Diffusion Models (CVPR 2024) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Marcos-Manchon_Open-Vocabulary_Attention_Maps_with_Token_Optimization_for_Semantic_Segmentation_in_CVPR_2024_paper.pdf)]

* The Devil is in the Fine-Grained Details: Evaluating Open-Vocabulary Object Detectors for Fine-Grained Understanding (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2311.17518)]

* Active Open-Vocabulary Recognition: Let Intelligent Moving Mitigate CLIP Limitations (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2311.17938)]

* Visual Programming for Zero-shot Open-Vocabulary 3D Visual Grounding (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2311.15383)]

* CAT-Seg: Cost Aggregation for Open-Vocabulary Semantic Segmentation (CVPR 2024) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Cho_CAT-Seg_Cost_Aggregation_for_Open-Vocabulary_Semantic_Segmentation_CVPR_2024_paper.pdf)]

* Image-to-Image Matching via Foundation Models: A New Perspective for Open-Vocabulary Semantic Segmentation (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2404.00262)]

* Open3DIS: Open-Vocabulary 3D Instance Segmentation with 2D Mask Guidance (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2312.10671)] (CVPR 2024)

* Open-Vocabulary Semantic Segmentation with Image Embedding Balancing (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2406.09829)] (CVPR 2024)

* Learning Background Prompts to Discover Implicit Knowledge for Open Vocabulary Object Detection (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2406.00510)] (CVPR 2024)

* AnySkill: Learning Open-Vocabulary Physical Skill for Interactive Agents (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2403.12835)] (CVPR 2024)

* Scene-adaptive and Region-aware Multi-modal Prompt for Open Vocabulary Object Detection (CVPR 2024) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhao_Scene-adaptive_and_Region-aware_Multi-modal_Prompt_for_Open_Vocabulary_Object_Detection_CVPR_2024_paper.pdf)] (CVPR 2024) 


* Training-Free Open-Vocabulary Segmentation with Offline Diffusion-Augmented Prototype Generation (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2404.06542)] (CVPR 2024)

* YOLO-World: Real-Time Open-Vocabulary Object Detection (CVPR 2024) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Cheng_YOLO-World_Real-Time_Open-Vocabulary_Object_Detection_CVPR_2024_paper.pdf)] (CVPR 2024)

* Open-Vocabulary Object 6D Pose Estimation (CVPR 2024) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Corsetti_Open-Vocabulary_Object_6D_Pose_Estimation_CVPR_2024_paper.pdf)]

* Taming Self-Training for Open-Vocabulary Object Detection (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2308.06412)]

* OVMR: Open-Vocabulary Recognition with Multi-Modal References (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2406.04675)]

* Retrieval-Augmented Open-Vocabulary Object Detection (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2404.05687)]

* Language Embedded 3D Gaussians for Open-Vocabulary Scene Understanding (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2311.18482)]

* Transferable and Principled Efficiency for Open-Vocabulary Segmentation (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2404.07448)]

* From Pixels to Graphs: Open-Vocabulary Scene Graph Generation with Vision-Language Models (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2404.00906)]

* Exploring the Potential of Large Foundation Models for Open-Vocabulary HOI Detection (CVPR 2024) 
[[Paper](http://arxiv.org/abs/2404.06194)]

### 2023 Papers
#### CVPR
* OpenScene: 3D Scene Understanding with Open Vocabularies (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2211.15654)]

* Open-Vocabulary Point-Cloud Object Detection without 3D Annotation (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2304.00788)]

* Learning to Generate Language-supervised and Open-vocabulary Scene Graph using Pre-trained Visual-Semantic Space (CVPR 2023) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Learning_To_Generate_Language-Supervised_and_Open-Vocabulary_Scene_Graph_Using_Pre-Trained_CVPR_2023_paper.html)]

* Side Adapter Network for Open-Vocabulary Semantic Segmentation (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2302.12242)]

* Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion Models (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2303.04803)]

* Mask-free OVIS: Open-Vocabulary Instance Segmentation without Manual Mask Annotations (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2303.16891)]

* Open-Vocabulary Semantic Segmentation with Mask-adapted CLIP (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2210.04150)]

* Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers (CVPR 2023) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Kim_Region-Aware_Pretraining_for_Open-Vocabulary_Object_Detection_With_Vision_Transformers_CVPR_2023_paper.html)]

* Object-Aware Distillation Pyramid for Open-Vocabulary Object Detection (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2303.05892)]

* Aligning Bag of Regions for Open-Vocabulary Object Detection (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2302.13996)]

* Open-set Fine-grained Retrieval via Prompting Vision-Language Evaluator (CVPR 2023) 
[[Paper](https://readpaper.com/paper/1608794558669368064)]

* Open Vocabulary Semantic Segmentation with Patch Aligned Contrastive Learning (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2212.04994)]

* FreeSeg: Unified, Universal and Open-Vocabulary Image Segmentation (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2303.17225)]

* GLIGEN: Open-Set Grounded Text-to-Image Generation (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2301.07093)]

* DetCLIPv2: Scalable Open-Vocabulary Object Detection Pre-training via Word-Region Alignment (CVPR 2023) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Yao_DetCLIPv2_Scalable_Open-Vocabulary_Object_Detection_Pre-Training_via_Word-Region_Alignment_CVPR_2023_paper.html)]

* OvarNet: Towards Open-vocabulary Object Attribute Recognition (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2301.09506)]

* PLA: Language-Driven Open-Vocabulary 3D Scene Understanding (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2211.16312)]

* Open-vocabulary Attribute Detection (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2211.12914)]

* Learning Open-vocabulary Semantic Segmentation Models From Natural Language Supervision (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2301.09121)]

* Learning to Generate Text-grounded Mask for Open-world Semantic Segmentation from Only Image-Text Pairs (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2212.00785)]

* CORA: Adapting CLIP for Open-Vocabulary Detection with Region Prompting and Anchor Pre-Matching (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2303.13076)]

* OVTrack: Open-Vocabulary Multiple Object Tracking (CVPR 2023) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Li_OVTrack_Open-Vocabulary_Multiple_Object_Tracking_CVPR_2023_paper.html)]

* Learning to Detect and Segment for Open Vocabulary Object Detection (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2212.12130)]

* Learning to Detect and Segment for Open Vocabulary Object Detection (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2212.12130)]


#### ICLR
* Open-vocabulary Object Detection via Vision and Language Knowledge Distillation	(ICLR 2023) 
[[Paper](https://openreview.net/forum?id=lL3lnMbR4WU)]
[[Code](https://github.com/tensorflow/tpu/tree/master/models/official/detection/projects/vild)]<br>
*Datasets: LVIS, PASCAL VOC, COCO, Objects365*<br>
*Task: Object Detection*
<!--#### NeurIPS-->

#### ICCV

* Global Knowledge Calibration for Fast Open-Vocabulary Segmentation (ICCV 2023) 
[[Paper](https://arxiv.org/abs/2303.09181)]

* Open-vocabulary Panoptic Segmentation with Embedding Modulation (ICCV 2023) 
[[Paper](https://arxiv.org/abs/2303.11324)]

#### ICML
* SegCLIP: Patch Aggregation with Learnable Centers for Open-Vocabulary Semantic Segmentation (ICML 2023) 
[[Paper](https://arxiv.org/abs/2211.14813)]

* Open-VCLIP: Transforming CLIP to an Open-vocabulary Video Model via Interpolated Weight Optimization (ICML 2023) 
[[Paper](https://arxiv.org/abs/2302.00624)]

* Open-Vocabulary Universal Image Segmentation with MaskCLIP (ICML 2023) 
[[Paper](http://arxiv.org/abs/2208.08984)]

* Multi-Modal Classifiers for Open-Vocabulary Object Detection (ICML 2023) 
[[Paper](http://arxiv.org/abs/2207.01887)]

<!--#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI-->
#### CVPRw
* Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion Models (CVPRw 2023) 
[[Paper](https://arxiv.org/abs/2303.04803)]
<!--#### WACV
#### IJCV
#### BMVC
#### ICCw -->
#### Arxiv & Others

* A Language-Guided Benchmark for Weakly Supervised Open Vocabulary Semantic Segmentation	(Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2302.14163)]

* Aligning Bag of Regions for Open-Vocabulary Object Detection (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2302.13996)]

* From Occlusion to Insight: Object Search in Semantic Shelves using Large Language Models (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2302.12915)]

* Side Adapter Network for Open-Vocabulary Semantic Segmentation (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2302.12242)]

* CHiLS: Zero-Shot Image Classification with Hierarchical Label Sets (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2302.02551)]

<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2022 Papers
#### CVPR
* Open-Vocabulary One-Stage Detection with Hierarchical Visual-Language Knowledge Distillation	(CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Open-Vocabulary_One-Stage_Detection_With_Hierarchical_Visual-Language_Knowledge_Distillation_CVPR_2022_paper.pdf)]
[[Code](https://github.com/mengqiDyangge/HierKD)]<br>
*Datasets: MS COCO*<br>
*Task: Object Detection*

* Open-Vocabulary Instance Segmentation via Robust Cross-Modal Pseudo-Labeling	(CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Huynh_Open-Vocabulary_Instance_Segmentation_via_Robust_Cross-Modal_Pseudo-Labeling_CVPR_2022_paper.pdf)]
[[Code](https://github.com/hbdat/cvpr22_cross_modal_pseudo_labeling)]<br>
*Datasets: MS-COCO, Open Images, Conceptual Caption*<br>
*Task: Instance segmentation*

* Learning to Prompt for Open-Vocabulary Object Detection with Vision-Language Model (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Du_Learning_To_Prompt_for_Open-Vocabulary_Object_Detection_With_Vision-Language_Model_CVPR_2022_paper.pdf)]
[[Code](https://github.com/dyabel/detpro)]<br>
*Datasets: LVIS v1, Pascal  VOC  Dataset, COCO, Objects365  Dataset*<br>
*Task: Object detection and instance segmentation*

* NOC-REK: Novel Object Captioning With Retrieved Vocabulary From External Knowledge (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Vo_NOC-REK_Novel_Object_Captioning_With_Retrieved_Vocabulary_From_External_Knowledge_CVPR_2022_paper.pdf)]<br>
*Datasets: COCO, Nocaps*<br>
*Task: Novel Object Captioning*

<!--#### ICLR-->
#### NeurIPS
* Patching open-vocabulary models by interpolating weights (NeurIPS 2022) 
[[Paper](https://openreview.net/forum?id=uOQNvEfjpaC)]
[[Code](https://github.com/mlfoundations/patching)]<br>
*Datasets: Cars, DTD, EuroSAT, GTSRB, KITTI, MNIST, RESISC45, SUN397, and SVHN. We use the remaining tasks as supported tasks: CIFAR10, CIFAR100, Food101, ImageNet, and STL10*<br>
*Task: Model Patching*

* Bridging the Gap between Object and Image-level Representations for Open-Vocabulary Detection (NeurIPS 2022) 
[[Paper](https://openreview.net/forum?id=aKXBrj0DHm)]
[[Code](https://github.com/hanoonaR/object-centric-ovd)]<br>
*Datasets: COCO, LVIS v1.0, OpenImages, Objects365*<br>
*Task: Object Detection*

* Paraphrasing Is All You Need for Novel Object Captioning (NeurIPS 2022) 
[[Paper](https://arxiv.org/abs/2209.12343)]<br>
*Datasets:  Open Images V4, COCO Captions 2017*<br>
*Task: Image Captioning*

<!--#### ICCV
#### ICML
#### IEEE-Access-->
#### ECCV

* PromptDet: Towards Open-vocabulary Detection using Uncurated Images	(ECCV 2022) 
[[Paper](https://arxiv.org/pdf/2203.16513v2.pdf)]
[[Code](https://fcjian.github.io/promptdet)]<br>
*Datasets: LVIS, LAION-400M and LAION-Novel, COCO*<br>
*Task: Object Detection*

* Scaling Open-vocabulary Image Segmentation with Image-level Labels (ECCV 2022) 
[[Paper](https://arxiv.org/pdf/2112.12143v2.pdf)]<br>
*Datasets: COCO, Localized Narrative (Loc. Narr.) test: PASCAL Context, PASCAL  VOC, ADE20k*<br>
*Task: Instance segmentation*

* Towards Open-vocabulary Scene Graph Generation with Prompt-based Finetuning (ECCV 2022) 
[[Paper](https://arxiv.org/pdf/2208.08165v3.pdf)]<br>
*Datasets: Visual Genome(VG), GQA, Open-Image*<br>
*Task: Scene Graph Generation*

* Simple Open-Vocabulary Object Detection with Vision Transformers (ECCV 2022) 
[[Paper](https://arxiv.org/pdf/2205.06230v2.pdf)]
[[Code](https://github.com/google-research/scenic/tree/main/scenic/projects/owl_vit)]<br>
*Datasets: OpenImages V4 (OI), Objects 365 (O365),and/or Visual Genome (VG) - Evaluation: COCO, LVIS, and O365*<br>
*Task: Object Detection*

* Open Vocabulary Object Detection with Pseudo Bounding-Box Labels (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136700263.pdf)]
[[Code](https://github.com/salesforce/PB-OVD)]<br>
*Datasets: COCO Caption, Visual-Genome, and SBU Caption (Object names:  COCO,  PASCAL  VOC,  Objects365 and LVIS)*<br>
*Task: Object Detection*

* Open-Vocabulary DETR with Conditional Matching (ECCV 2022 Oral) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136690107.pdf)]
[[Code](https://github.com/yuhangzang/OV-DETR)]<br>
*Datasets: LVIS, COCO*<br>
*Task: Object Detection*

* Improving Closed and Open-Vocabulary Attribute Prediction using Transformers (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136850199.pdf)]
[[Code](https://vkhoi.github.io/TAP)]<br>
*Datasets: VAW (closed-set) LSA common, LSA commonâ†’rare, HICO*<br>
*Task: Attribute Prediction*

* A Simple Baseline for Open Vocabulary Semantic Segmentation with Pre-trained Vision-language Model (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136890725.pdf)]
[[Code](https://github.com/MendelXu/zsseg.baseline)]<br>
*Datasets: COCO Stuff; Pascal VOC 2012; Cityscapes; Pascal Context; ADE20K*<br>
*Task: Semantic Segmentation*

* A Dataset for Interactive Vision-Language Navigation with Unknown Command Feasibility (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136680304.pdf)]
[[Code](https://github.com/aburns4/MoTIF)]<br>
*Datasets: MoTIF*<br>
*Task: Vision-Language Navigation (Apps)*

* Acknowledging the Unknown for Multi-label Learning with Single Positive Labels (ECCV 2022) 
[[Paper](https://arxiv.org/abs/2203.16219v2)]
[[Code](https://github.com/Correr-Zhou/SPML-AckTheUnknown)]<br>
*Datasets: PASCAL VOC 2012 (VOC), MS-COCO 2014 (COCO), NUS-WIDE (NUS), and CUB-200-2011 (CUB)*<br>
*Task: Single Positive Multi-label Learning*

#### AAAI
* OVIS: Open-Vocabulary Visual Instance Search via Visual-Semantic Aligned Representation Learning (AAAI 2022) 
[[Paper](https://ojs.aaai.org/index.php/AAAI/article/download/20070/version/18367/19829)]<br>
*Datasets: OVIS40; OVIS1600*<br>
*Task: Visual Instance Search*

* Open Vocabulary Electroencephalography-to-Text Decoding and Zero-Shot Sentiment Classification (AAAI 2022) 
[[Paper](https://arxiv.org/abs/2112.02690)]
[[Code](https://github.com/MikeWangWZHL/EEG-To-Text)]<br>
*Datasets: ZuCo*<br>
*Task: Brain Signals Language Decoding*

<!--#### TPAMI
#### CVPRw-->
#### WACV

* From Node To Graph: Joint Reasoning on Visual-Semantic Relational Graph for Zero-Shot Detection (WACV 2022) 
[[Paper](https://openaccess.thecvf.com/content/WACV2022/papers/Nie_From_Node_To_Graph_Joint_Reasoning_on_Visual-Semantic_Relational_Graph_WACV_2022_paper.pdf)]
[[Code](https://github.com/witnessai)]<br>
*Datasets: MSCOCO*<br>
*Task: Object Detection*

* Trading-Off Information Modalities in Zero-Shot Classification (WACV 2022) 
[[Paper](https://openaccess.thecvf.com/content/WACV2022/papers/Sanchez_Trading-Off_Information_Modalities_in_Zero-Shot_Classification_WACV_2022_paper.pdf)]
[[Code](http://github.com/jadrs/zsl)]<br>
*Datasets: Caltech UCSD Birds 200-2011 (CUB), Animals with Attributes 1 and 2 (AWA1 & AWA2), attribute Pascal & Yahoo (APY), SUN attributes (SUN) and Oxford flowers (FLO)*<br>
*Task: Image Classification*

<!--#### IJCV-->
#### BMVC
* Partially-Supervised Novel Object Captioning Using Context from Paired Data (BMVC 2022) 
[[Paper](https://arxiv.org/abs/2109.05115v2)]<br>
*Datasets: MS COCO*<br>
*Task: Object Captioning*

* Open-vocabulary Semantic Segmentation with Frozen Vision-Language Models (BMVC 2022) 
[[Paper](https://arxiv.org/pdf/2210.15138v1.pdf)]
[[Code](https://yyh-rain-song.github.io/Fusioner_webpage/)]<br>
*Datasets: : PASCAL-5i, COCO-20i, FSS-1000, Mosaic-4*<br>
*Task: Semantic Segmentation*
<!-- #### ICCw -->

#### Arxiv & Others
* Describing Sets of Images with Textual-PCA (EMNLP 2022) 
[[Paper](https://arxiv.org/pdf/2210.12112v1.pdf)]
[[Code](https://github.com/OdedH/textual-pca)]<br>
*Datasets: CelebA; Stanford Cars; COCO-Horses; LSUN-Church*<br>
*Task: Text Generation for Sets of Images*
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2021 Papers
#### CVPR
* Open-Vocabulary Object Detection Using Captions	(CVPR 2021) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Zareian_Open-Vocabulary_Object_Detection_Using_Captions_CVPR_2021_paper.pdf)]
[[Code](https://github.com/alirezazareian/ovr-cnn)]<br>
*Datasets: COCO Objects, COCO Captions*<br>
*Task: Object Detection*
<!--#### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### Older Papers
* A Latent Morphology Model for Open-Vocabulary Neural Machine Translation (ICLR 2020 Spotlight) 
[[Paper](https://openreview.net/forum?id=BJxSI1SKDH)]
[[Code](https://github.com/d-ataman/lmm)]<br>
*Datasets: Arabic (AR), Czech (CS) and Turkish (TR)*<br>
*Task: Neural Machine Translation*

* Open Vocabulary Learning on Source Code with a Graph-Structured Cache (ICML 2019) 
[[Paper](https://arxiv.org/abs/1810.08305)]<br>
*Datasets: Java source code*<br>
*Task: Java source code Learning*

* Visual Question Generation for Class Acquisition of Unknown Objects (ECCV 2018) 
[[Paper](https://www.ecva.net/papers/eccv_2018/papers_ECCV/papers/Kohei_Uehara_Visual_Question_Generation_ECCV_2018_paper.pdf)]
[[Code](https://github.com/mil-tokyo/vqg-unknown)]<br>
*Datasets: Visual Genome, ILSVRC2012, ILSVRC2010, WordNet*<br>
*Task: Visual Question Generation, Object Detection*

* Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input (ECCV 2018) 
[[Paper](https://www.ecva.net/papers/eccv_2018/papers_ECCV/papers/David_Harwath_Jointly_Discovering_Visual_ECCV_2018_paper.pdf)]
[[Code](http://groups.csail.mit.edu/sls/downloads/placesaudio/)]<br>
*Datasets: Places Audio Caption, ADE20k, MSCOCO*<br>
*Task: Audio-Visual Associative Localizations*

* Image Captioning with Unseen Objects (BMVC 2019) 
[[Paper](https://bmvc2019.org/wp-content/papers/0124.html)]<br>
*Datasets: COCO*<br>
*Task: Image Captioning*

* nocaps: novel object captioning at scale (ICCV 2019) 
[[Paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Agrawal_nocaps_novel_object_captioning_at_scale_ICCV_2019_paper.pdf)]
[[Code](https://nocaps.org)]<br>
*Datasets: nocaps, COCO Captions*<br>
*Task: Image Captioning*

* Pointing Novel Objects in Image Captioning (CVPR 2019) 
[[Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Pointing_Novel_Objects_in_Image_Captioning_CVPR_2019_paper.pdf)]<br>
*Datasets: held-out COCO, ImageNet*<br>
*Task: Image Captioning*

* Learning User Representations for Open Vocabulary Image Hashtag Prediction (CVPR 2020) 
[[Paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Durand_Learning_User_Representations_for_Open_Vocabulary_Image_Hashtag_Prediction_CVPR_2020_paper.pdf)]<br>
*Datasets: YFCC100M*<br>
*Task: Image Hashtag Prediction*

* Open-Edit: Open-Domain Image Manipulation with Open-Vocabulary Instructions (ECCV 2020) 
[[Paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123560086.pdf)]
[[Code](https://github.com/xh-liu/Open-Edit)]<br>
*Datasets: BSDS500, Conceptual Captions*<br>
*Task: Image Manipulation*

<!----------------------------------------------------------------------------------------------------------------------------------------------->
## Open Vocabulary Videos
<!----------------------------------------------------------------------------------------------------------------------------------------------->

### 2023 Papers
#### CVPR

* Open-Category Human-Object Interaction Pre-training via Language Modeling Framework (CVPR 2023) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Zheng_Open-Category_Human-Object_Interaction_Pre-Training_via_Language_Modeling_Framework_CVPR_2023_paper.html)]

* Being Comes from Not-being: Open-vocabulary Text-to-Motion Generation with Wordless Training (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2210.15929)]

* OVTrack: Open-Vocabulary Multiple Object Tracking (CVPR 2023) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Li_OVTrack_Open-Vocabulary_Multiple_Object_Tracking_CVPR_2023_paper.html)]
#### ICLR
* The Devil is in the Wrongly-classified Samples: Towards Unified Open-set Recognition (ICLR 2023) 
[[Paper](https://openreview.net/pdf?id=xLr0I_xYGAs)]<br>
*Datasets: CIFAR100, LSUN, MiTv2, UCF101, HMDB51*<br>
*Task: Image and Video Classification*
<!--#### NeurIPS
#### ICCV-->
#### ICML

* Open-VCLIP: Transforming CLIP to an Open-vocabulary Video Model via Interpolated Weight Optimization (ICML 2023) 
[[Paper](https://arxiv.org/abs/2302.00624)]

<!--#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw-->
#### Arxiv & Others

* Transforming CLIP to an Open-vocabulary Video Model via Interpolated Weight Optimization (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2302.00624)]

* TagCLIP: Improving Discrimination Ability of Open-Vocabulary Semantic Segmentation (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2304.07547)]

* MVP-SEG: Multi-View Prompt Learning for Open-Vocabulary Semantic Segmentation (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2304.06957)]

* Segment Everything Everywhere All at Once (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2304.06718)]

* Towards Open-Vocabulary Video Instance Segmentation (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2304.01715)]

* CLIP Surgery for Better Explainability with Enhancement in Open-Vocabulary Tasks (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2304.05653)]

* Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary Visual Recognition (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2304.04704)]

* V3Det: Vast Vocabulary Visual Detection Dataset (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2304.03752)]

* Token Merging for Fast Stable Diffusion (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.17604)]

* Going Beyond Nouns With Vision & Language Models Using Synthetic Data (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.17590)]

* MaMMUT: A Simple Architecture for Joint Learning for MultiModal Tasks (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.16839)]

* ZBS: Zero-shot Background Subtraction via Instance-level Background Modeling and Foreground Selection (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2303.14679)]

* Prompt-Guided Transformers for End-to-End Open-Vocabulary Object Detection (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.14386)]

* Three ways to improve feature alignment for open vocabulary detection (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.13518)]

* Zero-guidance Segmentation Using Zero Segment Labels (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.13396)]

* Open-Vocabulary Object Detection using Pseudo Caption Labels (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.13040)]

* Uni-Fusion: Universal Continuous Mapping (Arxiv 2023) 
[[Paper](https://arxiv.org/abs/2303.12678)]
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2022 Papers
<!-- #### CVPR
#### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw-->
#### Arxiv & Others

* Open-Vocabulary Temporal Action Detection with Off-the-Shelf Image-Text Features (Arxiv 2022) 
[[Paper](https://arxiv.org/abs/2212.10596)]

<!----------------------------------------------------------------------------------------------------------------------------------------------->
<!--### 2021 Papers
 #### CVPR
#### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->

