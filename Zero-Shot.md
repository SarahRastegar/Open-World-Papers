## Contents
- [Zero-Shot Learning](#Zero-Shot-Learning)
     - [Surveys](#Surveys)
     - [2023 Papers](#2023-Papers)
     - [2022 Papers](#2022-Papers)
     - [2021 Papers](#2021-Papers)
     - [2020 Papers](#2020-Papers)
     - [Older Papers](#Older-Papers)
- [Zero-Shot Learning Videos](#Zero-Shot-Learning-Videos)
     - [2023 Papers](#2023-Papers)
     - [2022 Papers](#2022-Papers)
     - [2021 Papers](#2021-Papers)
     - [Older Papers](#Older-Papers)

<!----------------------------------------------------------------------------------------------------------------------------------------------->
## Zero-Shot Learning
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### Surveys
* Zero-shot and Few-shot Learning with Knowledge Graphs: A Comprehensive Survey (Arxiv 2022) 
[[Paper](https://arxiv.org/abs/2112.10006)]

* A Survey of Zero-shot Generalisation in Deep Reinforcement Learning (JAIR 2023) 
[[Paper](https://arxiv.org/abs/2111.09794)]

* Survey of Visual-Semantic Embedding Methods for Zero-Shot Image Retrieval (ICMLA 2021) 
[[Paper](https://arxiv.org/abs/2105.07391)]

* Knowledge-aware Zero-Shot Learning: Survey and Perspective (IJCAI 2021 Survey Track) 
[[Paper](https://arxiv.org/abs/2103.00070)]

* A Survey of Deep Learning for Low-Shot Object Detection (Arxiv 2022) 
[[Paper](https://arxiv.org/abs/2112.02814)]

* Weak Novel Categories without Tears: A Survey on Weak-Shot Learning (Arxiv 2021) 
[[Paper](https://arxiv.org/abs/2110.02651)]

### 2023 Papers
#### CVPR

* Learning Attention as Disentangler for Compositional Zero-shot Learning (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2303.15111)]

* Delving into Shape-aware Zero-shot Semantic Segmentation (CVPR 2023) 
[[Paper](https://arxiv.org/abs/2304.08491)]

#### ICLR
* Relative representations enable zero-shot latent space communication (ICLR 2023 top 5%) 
[[Paper](https://openreview.net/forum?id=SrC-nwieGJ)]<br>
*Datasets: MNIST, F-MNIST, CIFAR-10, CIFAR-100, Cora, CiteSeer, PubMed, Amazon Reviews, TREC, DBpedia*<br>
*Task: Image Classification, Graph Node Classification, Image reconstruction, Text Classification*
<!--#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw-->
#### WACV
* Zero-Shot Versus Many-Shot: Unsupervised Texture Anomaly Detection (WACV 2023) 
[[Paper](https://openaccess.thecvf.com/content/WACV2023/papers/Aota_Zero-Shot_Versus_Many-Shot_Unsupervised_Texture_Anomaly_Detection_WACV_2023_paper.pdf)]
[[Code](https://drive.google.com/drive/folders/10OyPzvI3H6llCZBxKxFlKWt1Pw1tkMK1)]<br>
*Datasets: MVTec*<br>
*Task: Texture Anomaly Detection*

* Learning Attention Propagation for Compositional Zero-Shot Learning (WACV 2023) 
[[Paper](http://arxiv.org/abs/2210.11557)]<br>
*Datasets:  MIT-States, CGQA, UT-Zappos*<br>
*Task: Image Classification*

* InDiReCT: Language-Guided Zero-Shot Deep Metric Learning for Images (WACV 2023) 
[[Paper](http://arxiv.org/abs/2211.12760)]<br>
*Datasets: Synthetic Cars, Cars196*<br>
*Task: Deep Metric Learning Images*


<!--#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->

### 2022 Papers
#### CVPR
* KG-SP: Knowledge Guided Simple Primitivesfor Open World Compositional Zero-Shot Learning (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Karthik_KG-SP_Knowledge_Guided_Simple_Primitives_for_Open_World_Compositional_Zero-Shot_CVPR_2022_paper.pdf)]
[[Code](https://github.com/ExplainableML/KG-SP)]<br>
*Datasets: UT-Zappos, MIT-States, C-GQA*<br>
*Task: Compositional Zero-Shot Learning*

* Unseen Classes at a Later Time? No Problem (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Kuchibhotla_Unseen_Classes_at_a_Later_Time_No_Problem_CVPR_2022_paper.pdf)]<br>
*Datasets: AWA1  and  AWA2,  Attribute  Pascal  and  Yahoo(aPY), Caltech-UCSD-Birds 200-2011 (CUB) and SUN*<br>
*Task: Image Classification*

* Few-Shot Keypoint Detection With Uncertainty Learning for Unseen Species (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Few-Shot_Keypoint_Detection_With_Uncertainty_Learning_for_Unseen_Species_CVPR_2022_paper.pdf)]<br>
*Datasets: Animal  pose, CUB, NABird*<br>
*Task: Keypoint Detection*

* Distinguishing Unseen From Seen for Generalized Zero-Shot Learning (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Su_Distinguishing_Unseen_From_Seen_for_Generalized_Zero-Shot_Learning_CVPR_2022_paper.pdf)]<br>
*Datasets: Caltech-UCSD Birds-200-2011 (CUB), Ox-ford Flowers (FLO), SUN Attribute (SUN), Animals with Attributes 1 (AwA1) and Animals with Attributes 2(AwA2)*<br>
*Task: Image Classification*

* Siamese Contrastive Embedding Network for Compositional Zero-Shot Learning (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Siamese_Contrastive_Embedding_Network_for_Compositional_Zero-Shot_Learning_CVPR_2022_paper.pdf)]
[[Code](https://github.com/XDUxyLi/SCEN-master)]<br>
*Datasets: MIT-States, UT-Zappos, and C-GQA*<br>
*Task: Image Classification*

* ZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Tewel_ZeroCap_Zero-Shot_Image-to-Text_Generation_for_Visual-Semantic_Arithmetic_CVPR_2022_paper.pdf)]
[[Code](https://github.com/YoadTew/zero-shot-image-to-text)]<br>
*Datasets: COCO*<br>
*Task: Image Captioning*

* LiT: Zero-Shot Transfer With Locked-Image Text Tuning (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhai_LiT_Zero-Shot_Transfer_With_Locked-Image_Text_Tuning_CVPR_2022_paper.pdf)]<br>
*Datasets: CC12M; YFCC100m; ALIGN; ImageNet-v2, -R, -A, -ReaL, and ObjectNet, VTAB;  Cifar100; Pets; Wikipedia based Image Text (WIT)*<br>
*Task: Image-Text Retreival*

* Non-Generative Generalized Zero-Shot Learning via Task-Correlated Disentanglement and Controllable Samples Synthesis (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Non-Generative_Generalized_Zero-Shot_Learning_via_Task-Correlated_Disentanglement_and_Controllable_Samples_CVPR_2022_paper.pdf)]<br>
*Datasets: Animal with Attribute (AWA1), Animal with Attribute2 (AWA2), Caltech-UCSD Birds-200-2011(CUB), Oxford 102 flowers (FLO)*<br>
*Task: Image Classification*

* CLIP-Forge: Towards Zero-Shot Text-To-Shape Generation (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Sanghi_CLIP-Forge_Towards_Zero-Shot_Text-To-Shape_Generation_CVPR_2022_paper.pdf)]
[[Code](https://github.com/AutodeskAILab/Clip-Forge)]<br>
*Datasets: ShapeNet(v2) dataset*<br>
*Task: Text-To-Shape Generation*

* Zero-Shot Text-Guided Object Generation With Dream Fields (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Jain_Zero-Shot_Text-Guided_Object_Generation_With_Dream_Fields_CVPR_2022_paper.pdf)]
[[Code](https://ajayj.com/dreamfields)]<br>
*Datasets: COCO*<br>
*Task: Text-Guided Object Generation*

* En-Compactness: Self-Distillation Embedding & Contrastive Generation for Generalized Zero-Shot Learning (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Kong_En-Compactness_Self-Distillation_Embedding__Contrastive_Generation_for_Generalized_Zero-Shot_Learning_CVPR_2022_paper.pdf)]<br>
*Datasets: AWA1, AWA2, CUB, OxfordFlowers (FLO), Attributes  Pascal and Yahoo(APY)*<br>
*Task: Image Classification*

* VGSE: Visually-Grounded Semantic Embeddings for Zero-Shot Learning (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_VGSE_Visually-Grounded_Semantic_Embeddings_for_Zero-Shot_Learning_CVPR_2022_paper.pdf)]
[[Code](https://github.com/wenjiaXu/VGSE)]<br>
*Datasets: AWA2; CUB; SUN*<br>
*Task: Image Classification*

* Sketch3T: Test-Time Training for Zero-Shot SBIR (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Sain_Sketch3T_Test-Time_Training_for_Zero-Shot_SBIR_CVPR_2022_paper.pdf)]<br>
*Datasets: Sketchy;  TU-Berlin Extension*<br>
*Task: Sketch-Based Image Retrieval*

* MSDN: Mutually Semantic Distillation Network for Zero-Shot Learning (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_MSDN_Mutually_Semantic_Distillation_Network_for_Zero-Shot_Learning_CVPR_2022_paper.pdf)]
[[Code](https://anonymous.4open.science/r/MSDN)]<br>
*Datasets: CUB (Caltech  UCSD  Birds 200), SUN (SUN Attribute) and AWA2 (Animals with Attributes 2)*<br>
*Task: Image Classification*

* Decoupling Zero-Shot Semantic Segmentation (CVPR 2022) 
[[Paper](https://arxiv.org/pdf/2112.07910v2.pdf)]
[[Code](https://github.com/dingjiansw101/ZegFormer)]<br>
*Datasets: PASCAL VOC; COCO-Stuff*<br>
*Task: Semantic Segmentation*

* Robust Region Feature Synthesizer for Zero-Shot Object Detection (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Robust_Region_Feature_Synthesizer_for_Zero-Shot_Object_Detection_CVPR_2022_paper.pdf)]<br>
*Datasets: PASCAL VOC, COCO, and DIOR*<br>
*Task: Object Detection*

* IntraQ: Learning Synthetic Images With Intra-Class Heterogeneity for Zero-Shot Network Quantization (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_IntraQ_Learning_Synthetic_Images_With_Intra-Class_Heterogeneity_for_Zero-Shot_Network_CVPR_2022_paper.pdf)]
[[Code](https://github.com/zysxmu/IntraQ)]<br>
*Datasets: CIFAR-10/100; ImageNet*<br>
*Task: Zero-Shot Quantization*

* It's All in the Teacher: Zero-Shot Quantization Brought Closer to the Teacher (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Choi_Its_All_in_the_Teacher_Zero-Shot_Quantization_Brought_Closer_to_CVPR_2022_paper.pdf)]<br>
*Datasets: CIFAR-10/100; ImageNet*<br>
*Task: Zero-Shot Quantization*

* Robust Fine-Tuning of Zero-Shot Models (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Wortsman_Robust_Fine-Tuning_of_Zero-Shot_Models_CVPR_2022_paper.pdf)]<br>
*Datasets: ImageNet distribution shifts (ImageNetV2, ImageNet-R,ObjectNet, and ImageNet-A, ImageNet Sketch); CIFAR10.1 &10.2*<br>
*Task: Zero-Shot Distribution Shift Robustness*

* Neural Mean Discrepancy for Efficient Out-of-Distribution Detection (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Neural_Mean_Discrepancy_for_Efficient_Out-of-Distribution_Detection_CVPR_2022_paper.pdf)]<br>
*Datasets: CIFAR-10, CIFAR-100, SVHN, croppedImageNet,  cropped  LSUN,  iSUN,  and  Texture*<br>
*Task: Image Classification*

<!-- #### ICLR -->
#### NeurIPS
* Make an Omelette with Breaking Eggs: Zero-Shot Learning for Novel Attribute Synthesis (NeurIPS 2022) 
[[Paper](https://arxiv.org/pdf/2111.14182v5.pdf)]
[[Code](https://yuhsuanli.github.io/ZSLA)]<br>
*Datasets: Caltech-UCSD Birds-200-2011 (CUB Dataset), α-CLEVR*<br>
*Task: Image Classification*

* PatchComplete: Learning Multi-Resolution Patch Priors for 3D Shape Completion on Unseen Categories (NeurIPS 2022) 
[[Paper](https://arxiv.org/abs/2206.04916)]
[[Code](https://yuchenrao.github.io/projects/patchComplete/patchComplete.html)]<br>
*Datasets: ShapeNet, ScanNet, Scan2CAD*<br>
*Task: 3D Shape Reconstruction*

* Mining Unseen Classes via Regional Objectness: A Simple Baseline for Incremental Segmentation (NeurIPS 2022) 
[[Paper](https://arxiv.org/abs/2211.06866)]
[[Code](https://github.com/zkzhang98/MicroSeg)]<br>
*Datasets: Pascal VOC and ADE20K*<br>
*Task: Continual Image Classification*

<!-- #### ICCV
#### ICML
#### IEEE-Access -->
#### ECCV
* Zero-Shot Attribute Attacks on Fine-Grained Recognition Models (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136650257.pdf)]<br>
*Datasets: Caltech-UCSD Birds-200-2011(CUB), Animal with Attributes (AWA2) and SUN Attribute (SUN)*<br>
*Task: Image Classification*

* Zero-Shot Learning for Reflection Removal of Single 360-Degree Image (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136790523.pdf)]<br>
*Datasets: 30 test 360-degree images*<br>
*Task: Reflection Removal*

* Exploring Hierarchical Graph Representation for Large-Scale Zero-Shot Image Classification (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136800108.pdf)]
[[Code](https://kaiyi.me/p/hgrnet.html)]<br>
*Datasets: ImageNet-21K-D (D for Directed Acyclic Graph)*<br>
*Task: Image Classification*

* Learning Invariant Visual Representations for Compositional Zero-Shot Learning (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136840335.pdf)]
[[Code](https://github.com/PRIS-CV/IVR)]<br>
*Datasets: Mit-States; UT-Zappos50K; Clothing16K, and AO-CLEVr*<br>
*Task: Image Retrieval*

* 3D Compositional Zero-Shot Learning with DeCompositional Consensus (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136880704.pdf)]<br>
*Datasets: Compositional PartNet (C-PartNet)*<br>
*Task: Compositional Zero-Shot Segmentation*

* Zero-Shot Category-Level Object Pose Estimation (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136990509.pdf)]
[[Code](https://github.com/applied-ai-lab/zero-shot-pose)]<br>
*Datasets: Common Objects in 3D (CO3D); PoseContrast*<br>
*Task: Object Pose Estimation*

#### AAAI
* Open Vocabulary Electroencephalography-to-Text Decoding and Zero-Shot Sentiment Classification (AAAI 2022) 
[[Paper](https://arxiv.org/abs/2112.02690)]
[[Code](https://github.com/MikeWangWZHL/EEG-To-Text)]<br>
*Datasets:  ZuCo*<br>
*Task: Brain Signals Language Decoding*
<!--#### TPAMI-->
#### CVPRw
* Semantically Grounded Visual Embeddings for Zero-Shot Learning (CVPRw 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022W/MULA/papers/Nawaz_Semantically_Grounded_Visual_Embeddings_for_Zero-Shot_Learning_CVPRW_2022_paper.pdf)]<br>
*Datasets: CUB(312−d), AWA(85−d) and aPY(64−d); FLO*<br>
*Task: Semantic Embeddings*

* Zero-Shot Learning Using Multimodal Descriptions (CVPRw 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Mall_Zero-Shot_Learning_Using_Multimodal_Descriptions_CVPRW_2022_paper.pdf)]<br>
*Datasets: CUB-200-2011 (CUB), SUN attributes (SUN) and DeepFashion (DF)*<br>
*Task: Multimodal Zero-Shot*

#### WACV

* COCOA: Context-Conditional Adaptation for Recognizing Unseen Classes in Unseen Domains (WACV 2022) 
[[Paper](https://openaccess.thecvf.com/content/WACV2022/papers/Mangla_COCOA_Context-Conditional_Adaptation_for_Recognizing_Unseen_Classes_in_Unseen_Domains_WACV_2022_paper.pdf)]<br>
*Datasets: DomainNet, DomainNet-LS*<br>
*Task: Domain Generalization and Novel Class Discovery*
<!--#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->

### 2021 Papers
#### CVPR
* Counterfactual Zero-Shot and Open-Set Visual Recognition (CVPR 2021) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Yue_Counterfactual_Zero-Shot_and_Open-Set_Visual_Recognition_CVPR_2021_paper.pdf)]<br>
*Datasets: MNIST, SVHN,CIFAR10 and CIFAR100*<br>
*Task: Object Detection*
<!-- #### ICLR
#### NeurIPS-->
#### ICCV
* Prototypical Matching and Open Set Rejection for Zero-Shot Semantic Segmentation (ICCV 2021) 
[[Paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_Prototypical_Matching_and_Open_Set_Rejection_for_Zero-Shot_Semantic_Segmentation_ICCV_2021_paper.pdf)]<br>
*Datasets: Pascal VOC 2012, Pascal Context*<br>
*Task: Semantic Segmentation*

<!--#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV-->
#### BMVC

* Structured Latent Embeddings for Recognizing Unseen Classes in Unseen Domains (BMVC 2021) 
[[Paper](https://www.bmvc2021-virtualconference.com/assets/papers/1377.pdf)]<br>
*Datasets: DomainNet, DomainNet-LS*<br>
*Task: Domain Generalization*

<!--#### ICCw
#### Arxiv & Others-->
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2020 Papers
#### CVPR

* Discovering Human Interactions With Novel Objects via Zero-Shot Learning (CVPR 2020) 
[[Paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Discovering_Human_Interactions_With_Novel_Objects_via_Zero-Shot_Learning_CVPR_2020_paper.pdf)]
[[Code](https://github.com/scwangdyd/zero_shot_hoi)]<br>
*Datasets: V-COCO, HICO-DET*<br>
*Task: Human Object Interaction*

#### ICLR

* Locality and Compositionality in Zero-Shot Learning (ICLR 2020) 
[[Paper](https://openreview.net/forum?id=Hye_V0NKwr)]<br>
*Datasets: AwA2, CUB-200-2011*<br>
*Task: Image Classification*

* Learning to Group: A Bottom-Up Framework for 3D Part Discovery in Unseen Categories (ICLR 2020) 
[[Paper](https://openreview.net/forum?id=rkl8dlHYvB)]
[[Code](https://github.com/tiangeluo/Learning-to-Group)]<br>
*Datasets: PartNet*<br>
*Task: 3D Part Discovery*


#### ICML

* Safe Deep Semi-Supervised Learning for Unseen-Class Unlabeled Data (ICML 2020) 
[[Paper](https://proceedings.mlr.press/v119/guo20i.html)]
[[Code](http://www.lamda.nju.edu.cn/code_DS3L.ashx)]<br>
*Datasets: MNIST, CIFAR10*<br>
*Task: Image Classification*

* Hallucinative Topological Memory for Zero-Shot Visual Planning (ICML 2020) 
[[Paper](https://arxiv.org/abs/2002.12336)]<br>
*Datasets: Mujoco simulation (Block wall, Block  wall  with  complex  obstacle, Block insertion, Robot  manipulation)*<br>
*Task: Visual Planning*

* “Other-Play” for Zero-Shot Coordination (ICML 2020) 
[[Paper](https://arxiv.org/abs/2003.02979)]
[[Code](https://bit.ly/2vYkfI7)]<br>
*Datasets: “lever game”,  Hanabi with AI Agents*<br>
*Task: Zero-Shot Coordination*

#### ECCV

* A Boundary Based Out-of-Distribution Classifier for Generalized Zero-Shot Learning (ECCV 2020) 
[[Paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123690562.pdf)]<br>
*Datasets: AWA1, AWA2, CUB, FLO and SUN*<br>
*Task: Out-of-Distribution Image Classification*

* Towards Recognizing Unseen Categories in Unseen Domains (ECCV 2020) 
[[Paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123680460.pdf)]
[[Code](https://github.com/mancinimassimiliano/CuMix)]<br>
*Datasets: AWA, CUB, FLO and SUN, PACS*<br>
*Task: Out-of-Distribution Image Classification*
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### Older Papers

* Generalized Zero-shot Learning using Open Set Recognition (BMVC 2019) 
[[Paper](https://bmvc2019.org/wp-content/papers/0035.html)]<br>
*Datasets: AWA1, APY, FLO, and CUB*<br>
*Task: Image Classification*

* Image Captioning with Unseen Objects (BMVC 2019) 
[[Paper](https://bmvc2019.org/wp-content/papers/0124.html)]<br>
*Datasets: COCO*<br>
*Task: Image Captioning*

* Stacked Semantics-Guided Attention Model for Fine-Grained Zero-Shot Learning (NeurIPS 2018) 
[[Paper](https://papers.nips.cc/paper/2018/hash/9087b0efc7c7acd1ef7e153678809c77-Abstract.html)]<br>
*Datasets: CUB and NABird*<br>
*Task: Image Classification*

* MSplit LBI: Realizing Feature Selection and Dense Estimation Simultaneously in Few-shot and Zero-shot Learning (ICML 2018) 
[[Paper](http://proceedings.mlr.press/v80/zhao18c.html)]<br>
*Datasets: Animals with Attributes (AwA), Caltech-UCSD Birds-200-2011 (CUB) and ImageNet 2012/2010*<br>
*Task: Image Classification*


* Zero-Shot Visual Imitation (ICLR 2018 Oral) 
[[Paper](https://openreview.net/forum?id=BkisuzWRW)]
[[Code](https://github.com/pathak22/zeroshot-imitation)]<br>
*Datasets: Rope manipulation using Baxter robot, Navigation of a wheeled robot in cluttered office environments, Simulated 3D navigation*<br>
*Task: Imitation Learning*


<!----------------------------------------------------------------------------------------------------------------------------------------------->
## Zero-Shot Learning Videos
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### Surveys
* Zero-Shot Action Recognition in Videos: A Survey (Neurocomputing 2021) 
[[Paper](https://arxiv.org/abs/1909.06423)]<br>

* A Review of Generalized Zero-Shot Learning Methods (TPAMI 2022) 
[[Paper](https://arxiv.org/abs/2011.08641)]<br>

* Generalized Zero-Shot Learning for Action Recognition with Web-Scale Video Data (Arxiv 2017) 
[[Paper](https://arxiv.org/abs/1710.07455)]<br>

### 2023 Papers
<!-- #### CVPR
#### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw-->
#### WACV

* Language-Free Training for Zero-Shot Video Grounding (WACV 2023) 
[[Paper](http://arxiv.org/abs/2210.12977)]<br>
*Datasets: Charades-STA, ActivityNet Captions*<br>
*Task: Video Grounding*

* Semantics Guided Contrastive Learning of Transformers for Zero-Shot Temporal Activity Detection (WACV 2023) 
[[Paper](https://openaccess.thecvf.com/content/WACV2023/papers/Nag_Semantics_Guided_Contrastive_Learning_of_Transformers_for_Zero-Shot_Temporal_Activity_WACV_2023_paper.pdf)]<br>
*Datasets: Thumos’14 and Charades*<br>
*Task: Action Recognition*
<!--#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2022 Papers
#### CVPR
* Uni-Perceiver: Pre-Training Unified Architecture for Generic Perception for Zero-Shot and Few-Shot Tasks (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Uni-Perceiver_Pre-Training_Unified_Architecture_for_Generic_Perception_for_Zero-Shot_and_CVPR_2022_paper.pdf)]<br>
*Datasets: ImageNet-21k;  Kinetics-700 and Moments in Time;  BookCorpora & English  Wikipedia  (Books&Wiki)  and  PAQ; COCO Caption, SBUCaptions  (SBU),  Visual  Genome,  CC3M, CC12M and YFCC; Flickr30k, MSVD,VQA ,and GLUE*<br>
*Task: Image-Text Retreival; Image and Video Classification*

* Cross-Modal Representation Learning for Zero-Shot Action Recognition (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Cross-Modal_Representation_Learning_for_Zero-Shot_Action_Recognition_CVPR_2022_paper.pdf)]
[[Code](https://github.com/microsoft/ResT)]<br>
*Datasets: Kinetics ->  UCF101, HMDB51, and ActivityNet*<br>
*Task: Action Recognition*

* Audio-Visual Generalised Zero-Shot Learning With Cross-Modal Attention and Language (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Mercea_Audio-Visual_Generalised_Zero-Shot_Learning_With_Cross-Modal_Attention_and_Language_CVPR_2022_paper.pdf)]
[[Code](https://github.com/ExplainableML/AVCA-GZSL)]<br>
*Datasets: VGGSound; UCF101; ActivityNet*<br>
*Task: Action Recognition*

* Alignment-Uniformity Aware Representation Learning for Zero-Shot Video Classification (CVPR 2022) 
[[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Pu_Alignment-Uniformity_Aware_Representation_Learning_for_Zero-Shot_Video_Classification_CVPR_2022_paper.pdf)]
[[Code](https://github.com/ShipuLoveMili/CVPR2022-AURL)]<br>
*Datasets: Kinetics-700 -> UCF101, HMDB51*<br>
*Task: Action Recognition*

<!-- #### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access-->
#### ECCV
* Temporal and cross-modal attention foraudio-visual zero-shot learning (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136800474.pdf)]
[[Code](https://github.com/ExplainableML/TCAF-GZSL)]<br>
*Datasets: UCF-GZSL^cls, VGGSound-GZSL^cls, and ActivityNet-GZSL^cls1*<br>
*Task: Action Recognition*

* CLASTER: Clustering with Reinforcement Learning for Zero-Shot Action Recognition (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136800177.pdf)]
[[Code](https://sites.google.com/view/claster-zsl/home)]<br>
*Datasets: Olympic Sports; UCF-101; HMDB-51*<br>
*Task: Action Recognition*

* Rethinking Zero-Shot Action Recognition: Learning from Latent Atomic Actions (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136640102.pdf)]<br>
*Datasets: KineticsZSAR, HMDB51, and UCF101*<br>
*Task: Action Recognition*

* Zero-Shot Temporal Action Detection via Vision-Language Prompting (ECCV 2022) 
[[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136630667.pdf)]
[[Code](https://github.com/sauradip/STALE)]<br>
*Datasets: THUMOS14; ActivityNet v1.3*<br>
*Task: Temporal Action Detection (TAD)*
<!--#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV
#### BMVC
#### ICCw
#### Arxiv & Others-->
<!----------------------------------------------------------------------------------------------------------------------------------------------->
### 2021 Papers
#### CVPR
* Recognizing Actions in Videos From Unseen Viewpoints (CVPR 2021) 
[[Paper](http://arxiv.org/abs/2103.16516)]<br>
*Datasets: Human3.6M, MLB-YouTube, Toyota SmartHome (TSH), NTU-RGB-D*<br>
*Task: Action Recognition*
<!-- #### ICLR
#### NeurIPS
#### ICCV
#### ICML
#### IEEE-Access
#### ECCV
#### AAAI
#### TPAMI
#### CVPRw
#### WACV
#### IJCV-->
#### BMVC

* Zero-Shot Action Recognition from Diverse Object-Scene Compositions (BMVC 2021) 
[[Paper](https://www.bmvc2021-virtualconference.com/assets/papers/0739.pdf)]
[[Code](https://github.com/carlobretti/object-scene-compositions-for-actions)]<br>
*Datasets: UCF-101, Kinetics-400*<br>
*Task: Action Recognition*


<!--#### ICCw
#### Arxiv & Others-->

<!----------------------------------------------------------------------------------------------------------------------------------------------->

### Older Papers

* Out-Of-Distribution Detection for Generalized Zero-Shot Action Recognition (CVPR 2019) 
[[Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Mandal_Out-Of-Distribution_Detection_for_Generalized_Zero-Shot_Action_Recognition_CVPR_2019_paper.pdf)]
[[Code](https://github.com/naraysa/gzsl-od)]<br>
*Datasets: Olympic Sports, HMDB51 and UCF101*<br>
*Task: Action Recognition*
